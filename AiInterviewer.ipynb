{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9usQJxZce7p1WTXizqUUu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41bdd18401d84f14a5b79492a61b773a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d41f6b3c28dd4bf1abca6fab7e2102de",
              "IPY_MODEL_88bab11877a14008bf94f3a2ed0f82be",
              "IPY_MODEL_91327c4791af485a80de753c4426c42a"
            ],
            "layout": "IPY_MODEL_78ab12d31b8f417ab0ae1083f7d9bacb"
          }
        },
        "d41f6b3c28dd4bf1abca6fab7e2102de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11a6c27fff347808396493831adc96b",
            "placeholder": "​",
            "style": "IPY_MODEL_08a2451ae2194814945a255417d693d2",
            "value": "modules.json: 100%"
          }
        },
        "88bab11877a14008bf94f3a2ed0f82be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109fa6967a6a4b07a6043e593a669693",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b2c4f706b054786ad7e256550e2c153",
            "value": 229
          }
        },
        "91327c4791af485a80de753c4426c42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_581dc1ecb94945a8a55b0f562d9ad8b5",
            "placeholder": "​",
            "style": "IPY_MODEL_001110475e2b4f7880d025b812de0ef1",
            "value": " 229/229 [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "78ab12d31b8f417ab0ae1083f7d9bacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e11a6c27fff347808396493831adc96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a2451ae2194814945a255417d693d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109fa6967a6a4b07a6043e593a669693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2c4f706b054786ad7e256550e2c153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "581dc1ecb94945a8a55b0f562d9ad8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "001110475e2b4f7880d025b812de0ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33c529a33d774921b14eec357e358a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_689ad9de54e54eaebd799485ff76c319",
              "IPY_MODEL_d27e5da3690c45bc9131fe9d827c21eb",
              "IPY_MODEL_984e19d34d1d4bbaa18562271a349249"
            ],
            "layout": "IPY_MODEL_45dbb2f5758046b882be7e75905251ee"
          }
        },
        "689ad9de54e54eaebd799485ff76c319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba69d96037a474d8300f7c543fd76b0",
            "placeholder": "​",
            "style": "IPY_MODEL_be502a14a3804613890e389b25009082",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "d27e5da3690c45bc9131fe9d827c21eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0504d701a61d4591a731d5de098f4bd6",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0f12f203c5a40f0b21cfade1de9cd01",
            "value": 122
          }
        },
        "984e19d34d1d4bbaa18562271a349249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd4b33c3a1d241779e1875eab72cbdc0",
            "placeholder": "​",
            "style": "IPY_MODEL_dcd913eabe2545af9063b3680a2b658f",
            "value": " 122/122 [00:00&lt;00:00, 7.64kB/s]"
          }
        },
        "45dbb2f5758046b882be7e75905251ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba69d96037a474d8300f7c543fd76b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be502a14a3804613890e389b25009082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0504d701a61d4591a731d5de098f4bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0f12f203c5a40f0b21cfade1de9cd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd4b33c3a1d241779e1875eab72cbdc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd913eabe2545af9063b3680a2b658f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686d723aecfb4aabb585d6376421de8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5badccd363e5485e94b46dec2b1d1839",
              "IPY_MODEL_9c095c75703b491f8e08160eee023ccf",
              "IPY_MODEL_8cdb589956444551bd16a104f00f81c0"
            ],
            "layout": "IPY_MODEL_549883310a704371afcf17f1b7d71931"
          }
        },
        "5badccd363e5485e94b46dec2b1d1839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeac17a4a0de4ed397cfe573a1baf5c3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f126cd912548adb58fa761ba00ec4f",
            "value": "README.md: "
          }
        },
        "9c095c75703b491f8e08160eee023ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6083109a8c264d608e065ac2cf90f582",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17ee19ef7a5343d18630cc4e7b1c1487",
            "value": 1
          }
        },
        "8cdb589956444551bd16a104f00f81c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e46b2454805f4b45b8ac2046b877de60",
            "placeholder": "​",
            "style": "IPY_MODEL_86818d652219425ca4b17ca0a278f122",
            "value": " 3.73k/? [00:00&lt;00:00, 259kB/s]"
          }
        },
        "549883310a704371afcf17f1b7d71931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeac17a4a0de4ed397cfe573a1baf5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f126cd912548adb58fa761ba00ec4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6083109a8c264d608e065ac2cf90f582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "17ee19ef7a5343d18630cc4e7b1c1487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e46b2454805f4b45b8ac2046b877de60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86818d652219425ca4b17ca0a278f122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da806af71894753b0ca5b149235def9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8683418d207942c2ba075b48e992efc7",
              "IPY_MODEL_41e83befa6324251832d02194d39a3eb",
              "IPY_MODEL_82e8d1b7d05747c68123ada70fb09117"
            ],
            "layout": "IPY_MODEL_9c80ccbe67b54c0d920623f838e74b73"
          }
        },
        "8683418d207942c2ba075b48e992efc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b5d411f7c894e6d90b42263be1c17ab",
            "placeholder": "​",
            "style": "IPY_MODEL_91ab98528cbb4e4894bcec6b871d190c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "41e83befa6324251832d02194d39a3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f056040790d6405e8f9a88b7dd21d6de",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54c0533271594ff3963fa04f25df563f",
            "value": 53
          }
        },
        "82e8d1b7d05747c68123ada70fb09117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc1433b11ca44125833b777c25ca0a73",
            "placeholder": "​",
            "style": "IPY_MODEL_bbd3e53c5953468ba5058d2cfaafaff7",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.92kB/s]"
          }
        },
        "9c80ccbe67b54c0d920623f838e74b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b5d411f7c894e6d90b42263be1c17ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ab98528cbb4e4894bcec6b871d190c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f056040790d6405e8f9a88b7dd21d6de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c0533271594ff3963fa04f25df563f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc1433b11ca44125833b777c25ca0a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd3e53c5953468ba5058d2cfaafaff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32a51e073e2e41df9d2fa2526d217904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47fae1e5eb074baa9bec7bf7e9505d30",
              "IPY_MODEL_cb7b70313f30408a96d0f56887e287a0",
              "IPY_MODEL_742f56b0dfc14612a261d6535aefcf62"
            ],
            "layout": "IPY_MODEL_3b25aef405e4451b897b2bc76429156d"
          }
        },
        "47fae1e5eb074baa9bec7bf7e9505d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93bd6bf100b440c0935a59a29f0e930a",
            "placeholder": "​",
            "style": "IPY_MODEL_bcf72a37565842209434278654d2c15c",
            "value": "config.json: 100%"
          }
        },
        "cb7b70313f30408a96d0f56887e287a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43d8cdff579472083e8ba86ab8d24d8",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f908a7ee0834553a9ea4b92a19bf54b",
            "value": 615
          }
        },
        "742f56b0dfc14612a261d6535aefcf62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039cbe88b2f3444ca09008644609c194",
            "placeholder": "​",
            "style": "IPY_MODEL_8f372542aabf42edba6e2ee4ee31ac77",
            "value": " 615/615 [00:00&lt;00:00, 46.4kB/s]"
          }
        },
        "3b25aef405e4451b897b2bc76429156d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93bd6bf100b440c0935a59a29f0e930a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf72a37565842209434278654d2c15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f43d8cdff579472083e8ba86ab8d24d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f908a7ee0834553a9ea4b92a19bf54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "039cbe88b2f3444ca09008644609c194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f372542aabf42edba6e2ee4ee31ac77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea1943376ce4fde97eebfcdaad25b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_957a87dc3fe841aaab9dfd0887104309",
              "IPY_MODEL_e626ba997faf4633a7d5f873d6597961",
              "IPY_MODEL_fcf9845643e94f5a8e3da83088a7e7b6"
            ],
            "layout": "IPY_MODEL_0481c0fa9d524b2dad4d5072836107e4"
          }
        },
        "957a87dc3fe841aaab9dfd0887104309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce3e352a00e4024b1358ca641e34565",
            "placeholder": "​",
            "style": "IPY_MODEL_d2415e740e134c78bbbaa144058e89f3",
            "value": "model.safetensors: 100%"
          }
        },
        "e626ba997faf4633a7d5f873d6597961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_161c42c894bb4d72afd4024fead9c139",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7fb18ced7c8435bb53c99a59650795f",
            "value": 1340616616
          }
        },
        "fcf9845643e94f5a8e3da83088a7e7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bd5ca2c1cf454ba1c3467f6deb6bb9",
            "placeholder": "​",
            "style": "IPY_MODEL_40fc2008889146fe951dc50526e9415f",
            "value": " 1.34G/1.34G [00:17&lt;00:00, 133MB/s]"
          }
        },
        "0481c0fa9d524b2dad4d5072836107e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce3e352a00e4024b1358ca641e34565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2415e740e134c78bbbaa144058e89f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "161c42c894bb4d72afd4024fead9c139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fb18ced7c8435bb53c99a59650795f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8bd5ca2c1cf454ba1c3467f6deb6bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40fc2008889146fe951dc50526e9415f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eac9e528021e4ddba49a6fa06e51452b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1c6923d7de44d2e9ff120013b01883d",
              "IPY_MODEL_828515cf6f5a4826b10049179b351e30",
              "IPY_MODEL_60e0325f7a4a4913b0a333c696f3d69c"
            ],
            "layout": "IPY_MODEL_8a037776e93c4e21826c64d09888e54b"
          }
        },
        "f1c6923d7de44d2e9ff120013b01883d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c45e77dbd14751a21bfe582feb3cd4",
            "placeholder": "​",
            "style": "IPY_MODEL_f35ad84b5aab414e85c9b5191350136e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "828515cf6f5a4826b10049179b351e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa94a8ea0d2445a788af8ef92bb782a9",
            "max": 377,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7407cc32d4894d0880bf946c1dd3bfba",
            "value": 377
          }
        },
        "60e0325f7a4a4913b0a333c696f3d69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8b0cfb74de44aa9b1bc7b6e53a6b9ee",
            "placeholder": "​",
            "style": "IPY_MODEL_53b8de4e7cbb434b96a147d33aa8731c",
            "value": " 377/377 [00:00&lt;00:00, 18.7kB/s]"
          }
        },
        "8a037776e93c4e21826c64d09888e54b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c45e77dbd14751a21bfe582feb3cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35ad84b5aab414e85c9b5191350136e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa94a8ea0d2445a788af8ef92bb782a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7407cc32d4894d0880bf946c1dd3bfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8b0cfb74de44aa9b1bc7b6e53a6b9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b8de4e7cbb434b96a147d33aa8731c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec3995b9aef44f5aff913660c9b18f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6eb4fbec7b8474e8d72e60b35fd3111",
              "IPY_MODEL_eac4da4e15cb413b848716411b1d0d8f",
              "IPY_MODEL_f7595cc62dcd4089b9d75b4204674954"
            ],
            "layout": "IPY_MODEL_8e48c03024484c50b376b4bc6c4dc570"
          }
        },
        "a6eb4fbec7b8474e8d72e60b35fd3111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7589fc8b8984dd3bdc6c921adc58dfc",
            "placeholder": "​",
            "style": "IPY_MODEL_2b9450cf8fab498b8063077e2fa79528",
            "value": "vocab.txt: "
          }
        },
        "eac4da4e15cb413b848716411b1d0d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec099becb7fa443aa3ed4ba0093f2ada",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f1e04da837b4da0aab4344cf5436127",
            "value": 1
          }
        },
        "f7595cc62dcd4089b9d75b4204674954": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c6c0ebda3d4fd2ab342ffe99ae721f",
            "placeholder": "​",
            "style": "IPY_MODEL_4fdfc6368092481d8655b03f44e2179a",
            "value": " 232k/? [00:00&lt;00:00, 8.82MB/s]"
          }
        },
        "8e48c03024484c50b376b4bc6c4dc570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7589fc8b8984dd3bdc6c921adc58dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9450cf8fab498b8063077e2fa79528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec099becb7fa443aa3ed4ba0093f2ada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9f1e04da837b4da0aab4344cf5436127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9c6c0ebda3d4fd2ab342ffe99ae721f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fdfc6368092481d8655b03f44e2179a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b449b6bedb4436bb97618d18b8d20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec2594e4552e4b71b1bac11f81569ecc",
              "IPY_MODEL_313bac9b9f1f477cada8d1a7edeaa3c2",
              "IPY_MODEL_923764a2fe5b4c78ac90099ed39d61de"
            ],
            "layout": "IPY_MODEL_9677e355f5c9454f85df27d915407160"
          }
        },
        "ec2594e4552e4b71b1bac11f81569ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022d612fcc874e29aeb64a86609644e3",
            "placeholder": "​",
            "style": "IPY_MODEL_c01e04c14c37496db5f5bcf6f434182d",
            "value": "tokenizer.json: "
          }
        },
        "313bac9b9f1f477cada8d1a7edeaa3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153841afbd6d4604819d1d88912103ea",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_061dc108f631439aa044efb9a8b94d66",
            "value": 1
          }
        },
        "923764a2fe5b4c78ac90099ed39d61de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8d430de4cd417ebee5db41044dca40",
            "placeholder": "​",
            "style": "IPY_MODEL_9a1923ea8d984e069d0ace557ee0adda",
            "value": " 466k/? [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "9677e355f5c9454f85df27d915407160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022d612fcc874e29aeb64a86609644e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c01e04c14c37496db5f5bcf6f434182d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "153841afbd6d4604819d1d88912103ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "061dc108f631439aa044efb9a8b94d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb8d430de4cd417ebee5db41044dca40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1923ea8d984e069d0ace557ee0adda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4104793d57443fcafb9cbb439404e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_016294b8118b4292972e49652c5331f9",
              "IPY_MODEL_5e548376df5c4d65bf2edd5c09eddfc9",
              "IPY_MODEL_0682c1d7f9c743a7ad03573e830a1757"
            ],
            "layout": "IPY_MODEL_a7849c49ce0e4fe88bbbe625fcbeab9c"
          }
        },
        "016294b8118b4292972e49652c5331f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_586d40b66d0c489daf85b680eea008cf",
            "placeholder": "​",
            "style": "IPY_MODEL_5bebbfa981a3495aa3063a29de29fe4c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5e548376df5c4d65bf2edd5c09eddfc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4ef8e36f3de46d1991a9ecc2007dc3a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08ba9175809847ff8f4572431286cf76",
            "value": 112
          }
        },
        "0682c1d7f9c743a7ad03573e830a1757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e2a8abc1a8429485f29e1294107db8",
            "placeholder": "​",
            "style": "IPY_MODEL_31440f773ec14f2b8f91e34307123eb5",
            "value": " 112/112 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "a7849c49ce0e4fe88bbbe625fcbeab9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586d40b66d0c489daf85b680eea008cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bebbfa981a3495aa3063a29de29fe4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4ef8e36f3de46d1991a9ecc2007dc3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ba9175809847ff8f4572431286cf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18e2a8abc1a8429485f29e1294107db8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31440f773ec14f2b8f91e34307123eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d49506d4d7f4c76a3d2ffe48052f80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cde38b839ae64f98904db941bc6e9d8e",
              "IPY_MODEL_ef4d787609594c1a967e17163c456859",
              "IPY_MODEL_ba4c5ac491304957875083b22667dc2d"
            ],
            "layout": "IPY_MODEL_12663658d480483385b58dad904da978"
          }
        },
        "cde38b839ae64f98904db941bc6e9d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5f70bd42ad4b93952d18685a0ad284",
            "placeholder": "​",
            "style": "IPY_MODEL_65e957cff3f34c70bb047508b42914f6",
            "value": "config.json: 100%"
          }
        },
        "ef4d787609594c1a967e17163c456859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e6eba181d4b45829fa528565e6ad2bf",
            "max": 191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f86a6b1336c7492d8074eb0bab443493",
            "value": 191
          }
        },
        "ba4c5ac491304957875083b22667dc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_988e96fb25a24a62a1caf2efc1a21432",
            "placeholder": "​",
            "style": "IPY_MODEL_2683887577174da2ae87a4798e2d4ce3",
            "value": " 191/191 [00:00&lt;00:00, 16.5kB/s]"
          }
        },
        "12663658d480483385b58dad904da978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5f70bd42ad4b93952d18685a0ad284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e957cff3f34c70bb047508b42914f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e6eba181d4b45829fa528565e6ad2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86a6b1336c7492d8074eb0bab443493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "988e96fb25a24a62a1caf2efc1a21432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2683887577174da2ae87a4798e2d4ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamyHamrouni/context-engineering/blob/main/AiInterviewer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR_iie53EduM",
        "outputId": "b0669090-2475-499e-fa1f-b352e82132b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-1.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-1.0.2-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.2-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_core-1.0.3-py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.9/469.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.3 langgraph-1.0.2 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.2 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph-store-mongodb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rNkLy4fE4ow",
        "outputId": "8802a715-29a1-4b98-a551-ef0f7c699211"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph-store-mongodb\n",
            "  Downloading langgraph_store_mongodb-0.1.0-py3-none-any.whl.metadata (363 bytes)\n",
            "Collecting langchain-mongodb>=0.6.1 (from langgraph-store-mongodb)\n",
            "  Downloading langchain_mongodb-0.7.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.23 (from langgraph-store-mongodb)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langchain-core<1.0,>=0.3 (from langchain-mongodb>=0.6.1->langgraph-store-mongodb)\n",
            "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0,>=0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.3.11)\n",
            "Requirement already satisfied: langchain<1.0,>=0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.3.27)\n",
            "Requirement already satisfied: lark<2.0.0,>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-store-mongodb) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2.0.2)\n",
            "Collecting pymongo>=4.6.1 (from langchain-mongodb>=0.6.1->langgraph-store-mongodb)\n",
            "  Downloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.23->langgraph-store-mongodb) (1.11.0)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.4.38)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (25.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=4.6.1->langchain-mongodb>=0.6.1->langgraph-store-mongodb)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<1.0,>=0.3->langchain-mongodb>=0.6.1->langgraph-store-mongodb) (1.3.1)\n",
            "Downloading langgraph_store_mongodb-0.1.0-py3-none-any.whl (9.1 kB)\n",
            "Downloading langchain_mongodb-0.7.2-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.15.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo, langchain-core, langgraph-checkpoint, langchain-mongodb, langgraph-store-mongodb\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.3\n",
            "    Uninstalling langchain-core-1.0.3:\n",
            "      Successfully uninstalled langchain-core-1.0.3\n",
            "  Attempting uninstall: langgraph-checkpoint\n",
            "    Found existing installation: langgraph-checkpoint 3.0.0\n",
            "    Uninstalling langgraph-checkpoint-3.0.0:\n",
            "      Successfully uninstalled langgraph-checkpoint-3.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.2 requires langchain-core>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dnspython-2.8.0 langchain-core-0.3.79 langchain-mongodb-0.7.2 langgraph-checkpoint-2.1.2 langgraph-store-mongodb-0.1.0 pymongo-4.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U pymongo langgraph langgraph-checkpoint-mongodb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJBcsJibUlvH",
        "outputId": "a0ce4000-a061-49e1-89a8-bbc37f8383f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.12/dist-packages (4.15.3)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Collecting langgraph-checkpoint-mongodb\n",
            "  Downloading langgraph_checkpoint_mongodb-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pymongo) (2.8.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langchain-mongodb>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint-mongodb) (0.7.2)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0,>=0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb) (0.3.11)\n",
            "Requirement already satisfied: langchain<1.0,>=0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb) (0.3.27)\n",
            "Requirement already satisfied: lark<2.0.0,>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb) (2.0.2)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n",
            "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Using cached langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langchain-mongodb>=0.6.1 (from langgraph-checkpoint-mongodb)\n",
            "  Using cached langchain_mongodb-0.7.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_mongodb-0.7.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Using cached langchain_core-1.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain>=0.3 (from langchain-mongodb>=0.6.1->langgraph-checkpoint-mongodb)\n",
            "  Downloading langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph_checkpoint_mongodb-0.2.1-py3-none-any.whl (12 kB)\n",
            "Downloading langchain_mongodb-0.7.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m942.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langchain_core-1.0.3-py3-none-any.whl (469 kB)\n",
            "Downloading langchain-1.0.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain, langchain-mongodb, langgraph-checkpoint-mongodb\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "  Attempting uninstall: langchain-mongodb\n",
            "    Found existing installation: langchain-mongodb 0.7.2\n",
            "    Uninstalling langchain-mongodb-0.7.2:\n",
            "      Successfully uninstalled langchain-mongodb-0.7.2\n",
            "Successfully installed langchain-1.0.3 langchain-core-1.0.3 langchain-mongodb-0.7.1 langgraph-checkpoint-mongodb-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptOwlsHEFD2R",
        "outputId": "d2c23e57-7ff5-4e04-a6d0-70f8f6167e28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain_community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain_community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.38)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-text-splitters-1.0.0 langchain_community-0.4.1 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get Tavily API key\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "# Get OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "1jfbqIU8Eoq0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context Manager for short term memory**"
      ],
      "metadata": {
        "id": "WxTROf8ARE2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any, Optional, Type, TypeVar\n",
        "\n",
        "class ContextManager:\n",
        "    def __init__(self,messages:List,tools:List):\n",
        "        self.messages = messages\n",
        "        self.tools = tools\n",
        "\n",
        "    def add_message(self, role: str, content: str):\n",
        "        self.messages.append({\"role\": role, \"content\": content})\n"
      ],
      "metadata": {
        "id": "0JJhc9r2Qrrx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Formatting**"
      ],
      "metadata": {
        "id": "3KMXYUQTRZhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "def create_expanded_context(\n",
        "        base_prompt: str,\n",
        "        role: Optional[str] = None,\n",
        "        examples: Optional[List[str]] = None,\n",
        "        constraints: Optional[List[str]] = None,\n",
        "        audience: Optional[str] = None,\n",
        "        tone: Optional[str] = None,\n",
        "        output_format: Optional[str] = None\n",
        "    ) -> str:\n",
        "          \"\"\"\n",
        "          Create an expanded context from a base prompt with optional components.\n",
        "\n",
        "          Args:\n",
        "              base_prompt: The core instruction or question\n",
        "              role: Who the model should act as\n",
        "              examples: List of example outputs to guide the model\n",
        "              constraints: List of requirements or boundaries\n",
        "              audience: Who the output is intended for\n",
        "              tone: Desired tone of the response\n",
        "              output_format: Specific format requirements\n",
        "\n",
        "          Returns:\n",
        "              Expanded context as a string\n",
        "          \"\"\"\n",
        "          context_parts = []\n",
        "\n",
        "          # Add role if provided\n",
        "          if role:\n",
        "              context_parts.append(f\"You are {role}.\")\n",
        "\n",
        "          # Add base prompt\n",
        "          context_parts.append(base_prompt)\n",
        "\n",
        "          # Add audience if provided\n",
        "          if audience:\n",
        "              context_parts.append(f\"Your response should be suitable for {audience}.\")\n",
        "\n",
        "          # Add tone if provided\n",
        "          if tone:\n",
        "              context_parts.append(f\"Use a {tone} tone in your response.\")\n",
        "\n",
        "          # Add output format if provided\n",
        "          if output_format:\n",
        "              context_parts.append(f\"Format your response as {output_format}.\")\n",
        "\n",
        "          # Add constraints if provided\n",
        "          if constraints and len(constraints) > 0:\n",
        "              context_parts.append(\"Requirements:\")\n",
        "              for constraint in constraints:\n",
        "                  context_parts.append(f\"- {constraint}\")\n",
        "\n",
        "          # Add examples if provided\n",
        "          if examples and len(examples) > 0:\n",
        "              context_parts.append(\"Examples:\")\n",
        "              for i, example in enumerate(examples, 1):\n",
        "                  context_parts.append(f\"Example {i}:\\n{example}\")\n",
        "\n",
        "          # Join all parts with appropriate spacing\n",
        "          expanded_context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "          return expanded_context"
      ],
      "metadata": {
        "id": "Z69ZFP9XRgHF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding client**"
      ],
      "metadata": {
        "id": "Nfh6D9VVRsl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.base import Embeddings\n",
        "import numpy as np\n",
        "\n",
        "class HFEmbeddingWrapper(Embeddings):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        return self.model.encode(texts, show_progress_bar=False, convert_to_numpy=True).tolist()\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        return self.model.encode([text], show_progress_bar=False, convert_to_numpy=True)[0].tolist()\n"
      ],
      "metadata": {
        "id": "bPPc3BPdGLtI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM Client**"
      ],
      "metadata": {
        "id": "jG8TC5weUKB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from openai import OpenAI\n",
        "from typing import List, Dict, Any, Optional, Type, TypeVar\n",
        "from pydantic import BaseModel\n",
        "import json\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "T = TypeVar(\"T\", bound=BaseModel)\n",
        "\n",
        "class LLMClient:\n",
        "    def __init__(self, base_url: str, api_key: str):\n",
        "        self.base_url = base_url\n",
        "        self.api_key = api_key\n",
        "        logger.info(f\"Initialized LLMClient with base_url: {self.base_url}\")\n",
        "\n",
        "    def completion(self, user_input: str, tools: List[Dict[str, Any]] = None) -> Any:\n",
        "        raise NotImplementedError(\"completion must be implemented by subclasses\")\n",
        "\n",
        "\n",
        "class OpenAIClient(LLMClient):\n",
        "    def __init__(self, model: str = \"gpt-4.1-mini\", temperature: float = 0.2,base_url: Optional[str] = None):\n",
        "        super().__init__(base_url, os.environ[\"OPENAI_API_KEY\"])\n",
        "        self.model = model\n",
        "        self.client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], base_url=base_url)\n",
        "        self.temperature = temperature\n",
        "        logger.info(f\"Initialized OpenAIClient with model: {self.model}, temperature: {self.temperature}\")\n",
        "\n",
        "\n",
        "    def completion(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        tools: Optional[List[Dict[str, Any]]] = None,\n",
        "        tool_choice: Optional[str] = None\n",
        "    ) -> Any:\n",
        "        params = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": self.temperature,\n",
        "            \"reasoning_effort\":\"low\"\n",
        "        }\n",
        "        logger.info(f\"Calling OpenAI completion with params: {params}\")\n",
        "\n",
        "        if tools is not None:\n",
        "            params[\"tools\"] = tools\n",
        "            params[\"tool_choice\"] = tool_choice or \"auto\"\n",
        "            logger.info(f\"Adding tools to completion params: {tools}\")\n",
        "\n",
        "\n",
        "        response = self.client.chat.completions.create(**params)\n",
        "        logger.info(\"Received response from OpenAI completion.\")\n",
        "        return response.choices[0].message\n",
        "\n",
        "    #  Structured output method\n",
        "    def structured_completion(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        schema: Type[T],\n",
        "        tools: Optional[List[Dict[str, Any]]] = None\n",
        "    ) -> T:\n",
        "        \"\"\"\n",
        "        Generate structured output that conforms to a given Pydantic schema.\n",
        "        \"\"\"\n",
        "        logger.info(\"Calling OpenAI structured completion.\")\n",
        "\n",
        "        params = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": self.temperature,\n",
        "        }\n",
        "        if tools is not None:\n",
        "            params[\"tools\"] = tools\n",
        "            params[\"tool_choice\"] = \"auto\"\n",
        "            logger.info(f\"Adding tools to structured completion params: {tools}\")\n",
        "        logger.debug(schema)\n",
        "        #params[\"response_format\"] = schema\n",
        "\n",
        "\n",
        "\n",
        "        logger.info(f\"Structured completion params: {params}\")\n",
        "\n",
        "\n",
        "        response = self.client.chat.completions.create(**params)\n",
        "        logger.info(\"Received response from OpenAI structured completion.\")\n",
        "\n",
        "\n",
        "        content = response.choices[0].message.content\n",
        "        logger.info(f\"Raw structured output: {content}\")\n",
        "        try:\n",
        "            data = json.loads(content)\n",
        "            logger.info(\"Successfully parsed structured output.\")\n",
        "            return schema.model_validate(data)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to parse structured output: {e}\\nRaw output: {content}\")\n",
        "            raise ValueError(f\"Failed to parse structured output: {e}\\nRaw output: {content}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "b6cxEY8hUc2E"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools**"
      ],
      "metadata": {
        "id": "YYylqQp6RxWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "qtAZxLuzW7VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.store.mongodb import MongoDBStore, create_vector_index_config\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "from langchain_core.tools import tool\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\"\"\"Models\"\"\"\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict, Optional\n",
        "from datetime import datetime\n",
        "\n",
        "class SubSkill(BaseModel):\n",
        "    name: str = Field(..., description=\"Name of the subskill (e.g., 'Data Structures', 'Communication')\")\n",
        "    description: str = Field(..., description=\"Brief explanation of the subskill and what it measures\")\n",
        "    strengths: List[str] = Field(..., description=\"List of key strong points, achievements, or evidence of proficiency\")\n",
        "    weaknesses: List[str] = Field(..., description=\"List of areas needing improvement or common pitfalls\")\n",
        "    growth_note: Optional[str] = Field(None, description=(\n",
        "        \"Suggestions or guidance for improvement in this subskill. \"\n",
        "        \"LLM can generate actionable advice.\"\n",
        "    ))\n",
        "    last_updated: Optional[datetime] = Field(None, description=(\n",
        "        \"Timestamp of the last update to this subskill. \"\n",
        "        \"LLM can populate dynamically when evaluation or notes change.\"\n",
        "    ))\n",
        "\n",
        "class TechnicalSkill(BaseModel):\n",
        "    name: str = Field(..., description=\"Main skill domain (e.g., 'SWE', 'ML', 'AI')\")\n",
        "    subskills: Dict[str, SubSkill] = Field(\n",
        "        default_factory=dict,\n",
        "        description=\"Mapping of subskill identifiers to SubSkill objects. \"\n",
        "    )\n",
        "\n",
        "class SoftSkill(BaseModel):\n",
        "    name: str = Field(..., description=\"Name of the soft skill category (e.g., 'Behavioral')\")\n",
        "    subskills: Dict[str, SubSkill] = Field(\n",
        "        default_factory=dict,\n",
        "        description=\"Mapping of soft subskill identifiers to SubSkill objects. \"\n",
        "    )\n",
        "\n",
        "class UserProfile(BaseModel):\n",
        "    name: str = Field(..., description=\"Full name of the user\")\n",
        "    title: str = Field(..., description=\"Current role or professional headline\")\n",
        "    technical_skills: Dict[str, TechnicalSkill] = Field(\n",
        "        default_factory=dict,\n",
        "        description=(\n",
        "            \"Mapping of technical skill domains to TechnicalSkill objects. \"\n",
        "            \"evaluation, evidence, growth_note, and last_updated are left for LLM to fill.\"\n",
        "        )\n",
        "    )\n",
        "    soft_skills: Dict[str, SoftSkill] = Field(\n",
        "        default_factory=dict,\n",
        "        description=(\n",
        "            \"Mapping of soft skill categories to SoftSkill objects. \"\n",
        "            \"evaluation, evidence, growth_note, and last_updated are left for LLM to fill.\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Embeddings & Store Config\"\"\"\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/nli-bert-large\")\n",
        "\n",
        "MONGODB_URI=\"mongodb+srv://mohamedramirahmani:1899neilaneila@cluster0.t7tyx.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "\n",
        "index_config = create_vector_index_config(\n",
        "    embed=embedding_model,\n",
        "    dims=1024,\n",
        "    relevance_score_fn=\"dotProduct\",   # works well with BERT-like embeddings\n",
        "    fields=[\"content\"]\n",
        ")\n",
        "\n",
        "#  Store & Retrieve Functions\n",
        "def save_candidate(profile: UserProfile, user_id: str):\n",
        "    \"\"\"Save or update a candidate profile to MongoDB vector memory.\"\"\"\n",
        "    if not user_id:\n",
        "        raise ValueError(\"User ID is required.\")\n",
        "    namespace = (user_id,)\n",
        "    candidate=None\n",
        "    try:\n",
        "        candidate = UserProfile(**profile)\n",
        "    except :\n",
        "        print(\"Invalid  User profile:\")\n",
        "        raise ValueError(\"Invalid candidate profile.\")\n",
        "\n",
        "    content = json.dumps(profile, indent=2)\n",
        "    print(\"Saving Profile ...\")\n",
        "\n",
        "\n",
        "    with MongoDBStore.from_conn_string(\n",
        "        conn_string=MONGODB_URI,\n",
        "        db_name=\"recruiter_ai_companion\",\n",
        "        collection_name=\"users\",\n",
        "        index_config=index_config,\n",
        "        auto_index_timeout=60\n",
        "    ) as store:\n",
        "        store.put(\n",
        "            namespace=namespace,\n",
        "            key=f\"profile\",\n",
        "            value={\"content\": content}\n",
        "        )\n",
        "\n",
        "    return f\"Candidate {candidate.name} saved\"\n",
        "\n",
        "\"\"\"@tool\n",
        "def retrieve_candidates(query: str, user_id: str, limit: int = 3):\n",
        "    Retrieve top-matching candidates using semantic similarity.\n",
        "    namespace = (user_id,)\n",
        "\n",
        "    with MongoDBStore.from_conn_string(\n",
        "        conn_string=MONGODB_URI,\n",
        "        db_name=\"recruiter_ai_companion\",\n",
        "        collection_name=\"user_profiles\",\n",
        "        index_config=index_config\n",
        "    ) as store:\n",
        "        results = store.search(namespace, query=query, limit=limit)\n",
        "\n",
        "    if not results:\n",
        "        return \"No matching candidates found.\"\n",
        "\n",
        "    profiles = []\n",
        "    for r in results:\n",
        "        data = json.loads(r.value[\"content\"])\n",
        "        profiles.append(UserProfile(**data))\n",
        "\n",
        "    return profiles\"\"\"\n",
        "def get_user(user_id: str):\n",
        "    \"\"\"Get a specific candidate profile by ID.\"\"\"\n",
        "    namespace = (user_id,)\n",
        "    with MongoDBStore.from_conn_string(\n",
        "        conn_string=MONGODB_URI,\n",
        "        db_name=\"recruiter_ai_companion\",\n",
        "        collection_name=\"users\",\n",
        "        index_config=index_config,\n",
        "        auto_index_timeout=60\n",
        "        ) as store:\n",
        "        try:\n",
        "            result = store.get(namespace=namespace, key=f\"profile\")\n",
        "            print(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error retrieving candidate: {e}\")\n",
        "            return None\n",
        "        if result:\n",
        "            data = json.loads(result.value[\"content\"])\n",
        "            return UserProfile(**data)"
      ],
      "metadata": {
        "id": "2fE7h1PYLdJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "41bdd18401d84f14a5b79492a61b773a",
            "d41f6b3c28dd4bf1abca6fab7e2102de",
            "88bab11877a14008bf94f3a2ed0f82be",
            "91327c4791af485a80de753c4426c42a",
            "78ab12d31b8f417ab0ae1083f7d9bacb",
            "e11a6c27fff347808396493831adc96b",
            "08a2451ae2194814945a255417d693d2",
            "109fa6967a6a4b07a6043e593a669693",
            "0b2c4f706b054786ad7e256550e2c153",
            "581dc1ecb94945a8a55b0f562d9ad8b5",
            "001110475e2b4f7880d025b812de0ef1",
            "33c529a33d774921b14eec357e358a85",
            "689ad9de54e54eaebd799485ff76c319",
            "d27e5da3690c45bc9131fe9d827c21eb",
            "984e19d34d1d4bbaa18562271a349249",
            "45dbb2f5758046b882be7e75905251ee",
            "4ba69d96037a474d8300f7c543fd76b0",
            "be502a14a3804613890e389b25009082",
            "0504d701a61d4591a731d5de098f4bd6",
            "c0f12f203c5a40f0b21cfade1de9cd01",
            "cd4b33c3a1d241779e1875eab72cbdc0",
            "dcd913eabe2545af9063b3680a2b658f",
            "686d723aecfb4aabb585d6376421de8e",
            "5badccd363e5485e94b46dec2b1d1839",
            "9c095c75703b491f8e08160eee023ccf",
            "8cdb589956444551bd16a104f00f81c0",
            "549883310a704371afcf17f1b7d71931",
            "aeac17a4a0de4ed397cfe573a1baf5c3",
            "f6f126cd912548adb58fa761ba00ec4f",
            "6083109a8c264d608e065ac2cf90f582",
            "17ee19ef7a5343d18630cc4e7b1c1487",
            "e46b2454805f4b45b8ac2046b877de60",
            "86818d652219425ca4b17ca0a278f122",
            "4da806af71894753b0ca5b149235def9",
            "8683418d207942c2ba075b48e992efc7",
            "41e83befa6324251832d02194d39a3eb",
            "82e8d1b7d05747c68123ada70fb09117",
            "9c80ccbe67b54c0d920623f838e74b73",
            "9b5d411f7c894e6d90b42263be1c17ab",
            "91ab98528cbb4e4894bcec6b871d190c",
            "f056040790d6405e8f9a88b7dd21d6de",
            "54c0533271594ff3963fa04f25df563f",
            "cc1433b11ca44125833b777c25ca0a73",
            "bbd3e53c5953468ba5058d2cfaafaff7",
            "32a51e073e2e41df9d2fa2526d217904",
            "47fae1e5eb074baa9bec7bf7e9505d30",
            "cb7b70313f30408a96d0f56887e287a0",
            "742f56b0dfc14612a261d6535aefcf62",
            "3b25aef405e4451b897b2bc76429156d",
            "93bd6bf100b440c0935a59a29f0e930a",
            "bcf72a37565842209434278654d2c15c",
            "f43d8cdff579472083e8ba86ab8d24d8",
            "3f908a7ee0834553a9ea4b92a19bf54b",
            "039cbe88b2f3444ca09008644609c194",
            "8f372542aabf42edba6e2ee4ee31ac77",
            "2ea1943376ce4fde97eebfcdaad25b0a",
            "957a87dc3fe841aaab9dfd0887104309",
            "e626ba997faf4633a7d5f873d6597961",
            "fcf9845643e94f5a8e3da83088a7e7b6",
            "0481c0fa9d524b2dad4d5072836107e4",
            "2ce3e352a00e4024b1358ca641e34565",
            "d2415e740e134c78bbbaa144058e89f3",
            "161c42c894bb4d72afd4024fead9c139",
            "a7fb18ced7c8435bb53c99a59650795f",
            "e8bd5ca2c1cf454ba1c3467f6deb6bb9",
            "40fc2008889146fe951dc50526e9415f",
            "eac9e528021e4ddba49a6fa06e51452b",
            "f1c6923d7de44d2e9ff120013b01883d",
            "828515cf6f5a4826b10049179b351e30",
            "60e0325f7a4a4913b0a333c696f3d69c",
            "8a037776e93c4e21826c64d09888e54b",
            "91c45e77dbd14751a21bfe582feb3cd4",
            "f35ad84b5aab414e85c9b5191350136e",
            "aa94a8ea0d2445a788af8ef92bb782a9",
            "7407cc32d4894d0880bf946c1dd3bfba",
            "c8b0cfb74de44aa9b1bc7b6e53a6b9ee",
            "53b8de4e7cbb434b96a147d33aa8731c",
            "aec3995b9aef44f5aff913660c9b18f6",
            "a6eb4fbec7b8474e8d72e60b35fd3111",
            "eac4da4e15cb413b848716411b1d0d8f",
            "f7595cc62dcd4089b9d75b4204674954",
            "8e48c03024484c50b376b4bc6c4dc570",
            "d7589fc8b8984dd3bdc6c921adc58dfc",
            "2b9450cf8fab498b8063077e2fa79528",
            "ec099becb7fa443aa3ed4ba0093f2ada",
            "9f1e04da837b4da0aab4344cf5436127",
            "a9c6c0ebda3d4fd2ab342ffe99ae721f",
            "4fdfc6368092481d8655b03f44e2179a",
            "b5b449b6bedb4436bb97618d18b8d20b",
            "ec2594e4552e4b71b1bac11f81569ecc",
            "313bac9b9f1f477cada8d1a7edeaa3c2",
            "923764a2fe5b4c78ac90099ed39d61de",
            "9677e355f5c9454f85df27d915407160",
            "022d612fcc874e29aeb64a86609644e3",
            "c01e04c14c37496db5f5bcf6f434182d",
            "153841afbd6d4604819d1d88912103ea",
            "061dc108f631439aa044efb9a8b94d66",
            "eb8d430de4cd417ebee5db41044dca40",
            "9a1923ea8d984e069d0ace557ee0adda",
            "b4104793d57443fcafb9cbb439404e70",
            "016294b8118b4292972e49652c5331f9",
            "5e548376df5c4d65bf2edd5c09eddfc9",
            "0682c1d7f9c743a7ad03573e830a1757",
            "a7849c49ce0e4fe88bbbe625fcbeab9c",
            "586d40b66d0c489daf85b680eea008cf",
            "5bebbfa981a3495aa3063a29de29fe4c",
            "d4ef8e36f3de46d1991a9ecc2007dc3a",
            "08ba9175809847ff8f4572431286cf76",
            "18e2a8abc1a8429485f29e1294107db8",
            "31440f773ec14f2b8f91e34307123eb5",
            "7d49506d4d7f4c76a3d2ffe48052f80c",
            "cde38b839ae64f98904db941bc6e9d8e",
            "ef4d787609594c1a967e17163c456859",
            "ba4c5ac491304957875083b22667dc2d",
            "12663658d480483385b58dad904da978",
            "7d5f70bd42ad4b93952d18685a0ad284",
            "65e957cff3f34c70bb047508b42914f6",
            "3e6eba181d4b45829fa528565e6ad2bf",
            "f86a6b1336c7492d8074eb0bab443493",
            "988e96fb25a24a62a1caf2efc1a21432",
            "2683887577174da2ae87a4798e2d4ce3"
          ]
        },
        "outputId": "0079b2ed-d8f0-4a17-ae03-a3a5e00f7dbd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3159757246.py:64: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/nli-bert-large\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41bdd18401d84f14a5b79492a61b773a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33c529a33d774921b14eec357e358a85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "686d723aecfb4aabb585d6376421de8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4da806af71894753b0ca5b149235def9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32a51e073e2e41df9d2fa2526d217904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ea1943376ce4fde97eebfcdaad25b0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/377 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eac9e528021e4ddba49a6fa06e51452b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aec3995b9aef44f5aff913660c9b18f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b449b6bedb4436bb97618d18b8d20b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4104793d57443fcafb9cbb439404e70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d49506d4d7f4c76a3d2ffe48052f80c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from datetime import datetime\n",
        "\n",
        "profile_data = {\n",
        "    \"name\": \"Mohamed Rami Hamrouni\",\n",
        "    \"title\": \"AI Engineer\",\n",
        "    \"technical_skills\": {\n",
        "        \"SWE\": {\n",
        "            \"name\": \"SWE\",\n",
        "            \"subskills\": {\n",
        "                \"data_structures\": {\n",
        "                    \"name\": \"Data Structures\",\n",
        "                    \"description\": \"Understanding of arrays, linked lists, trees, graphs, and their algorithms\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                },\n",
        "                \"system_design\": {\n",
        "                    \"name\": \"System Design\",\n",
        "                    \"description\": \"Ability to design scalable, maintainable software systems and understand architecture trade-offs\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                     \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                },\n",
        "                \"api_design\": {\n",
        "                    \"name\": \"API Design\",\n",
        "                    \"description\": \"Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"ML\": {\n",
        "            \"name\": \"ML\",\n",
        "            \"subskills\": {\n",
        "                \"fundamentals\": {\n",
        "                    \"name\": \"ML Fundamentals\",\n",
        "                    \"description\": \"Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                },\n",
        "                \"ml_system_design\": {\n",
        "                    \"name\": \"ML System Design\",\n",
        "                    \"description\": \"Designing machine learning pipelines, feature engineering, model deployment, and monitoring\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                     \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                },\n",
        "                \"ai\": {\n",
        "                    \"name\": \"AI / Advanced Topics\",\n",
        "                    \"description\": \"Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                     \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"soft_skills\": {\n",
        "        \"Behavioral\": {\n",
        "            \"name\": \"Behavioral\",\n",
        "            \"subskills\": {\n",
        "                \"communication\": {\n",
        "                    \"name\": \"Communication\",\n",
        "                    \"description\": \"Ability to clearly express ideas, structure answers effectively, and listen actively\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                     \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                },\n",
        "                \"teamwork\": {\n",
        "                    \"name\": \"Teamwork\",\n",
        "                    \"description\": \"Collaboration, conflict resolution, and working effectively within a team\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                     \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                },\n",
        "                \"adaptability\": {\n",
        "                    \"name\": \"Adaptability\",\n",
        "                    \"description\": \"Ability to adjust to new challenges, unexpected questions, and changing scenarios\",\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None,\n",
        "                     \"strengths\": [],\n",
        "                    \"weaknesses\": []\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "user = UserProfile(**profile_data)\n",
        "print(user.technical_skills)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQvlhyRwhKu2",
        "outputId": "971f3f91-f77d-4424-85dd-e3184ab429cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SWE': TechnicalSkill(name='SWE', subskills={'data_structures': SubSkill(name='Data Structures', description='Understanding of arrays, linked lists, trees, graphs, and their algorithms', strengths=[], weaknesses=[], growth_note=None, last_updated=None), 'system_design': SubSkill(name='System Design', description='Ability to design scalable, maintainable software systems and understand architecture trade-offs', strengths=[], weaknesses=[], growth_note=None, last_updated=None), 'api_design': SubSkill(name='API Design', description='Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation', strengths=[], weaknesses=[], growth_note=None, last_updated=None)}), 'ML': TechnicalSkill(name='ML', subskills={'fundamentals': SubSkill(name='ML Fundamentals', description='Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs', strengths=[], weaknesses=[], growth_note=None, last_updated=None), 'ml_system_design': SubSkill(name='ML System Design', description='Designing machine learning pipelines, feature engineering, model deployment, and monitoring', strengths=[], weaknesses=[], growth_note=None, last_updated=None), 'ai': SubSkill(name='AI / Advanced Topics', description='Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques', strengths=[], weaknesses=[], growth_note=None, last_updated=None)})}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d91914a"
      },
      "source": [
        "The `generate_tool_schema` function takes a dictionary representing the user profile and an optional tool name as input. It generates a JSON schema that describes the structure of the user profile, including technical and soft skills with all subskill fields. This schema can be used by language models to understand the structure of the data and populate the dynamic fields (strengths, weaknesses, growth_note, last_updated) during an interview or evaluation process."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any\n",
        "\n",
        "def generate_tool_schema(profile: Dict[str, Any], tool_name: str = \"save_candidate\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Converts a UserProfile-like dictionary into a full tool schema for LLMs,\n",
        "    including technical and soft skills with all subskill fields.\n",
        "    \"\"\"\n",
        "    def build_subskills_schema(subskills: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        props = {}\n",
        "        for key, val in subskills.items():\n",
        "            props[key] = {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"name\": {\"type\": \"string\", \"description\": val.get(\"name\", \"\")},\n",
        "                    \"description\": {\"type\": \"string\", \"description\": val.get(\"description\", \"\")},\n",
        "                    \"growth_note\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                        \"description\": (\n",
        "                            \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. \"\n",
        "                            \"Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. \"\n",
        "                            \"Null if no improvement note is available.\"\n",
        "                        )\n",
        "                    },\n",
        "                    \"last_updated\": {\n",
        "                        \"type\": [\"string\", \"null\"],\n",
        "                        \"description\": (\n",
        "                            \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last \"\n",
        "                            \"evaluated or modified. Null if never updated.\"\n",
        "                        )\n",
        "                    },\n",
        "                    \"strengths\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"string\"},\n",
        "                        \"description\": (\n",
        "                            \"A list of key strong points, achievements, or evidence of proficiency for this subskill. \"\n",
        "                            \"Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
        "                        )\n",
        "                    },\n",
        "                    \"weaknesses\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"string\"},\n",
        "                        \"description\": (\n",
        "                            \"A list of areas needing improvement or common pitfalls related to this subskill. \"\n",
        "                            \"Each item should be a short statement describing a limitation or growth opportunity \"\n",
        "                            \"(e.g., 'Limited experience with Kubernetes scaling').\"\n",
        "                        )\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"name\", \"description\",\"strengths\",\"weaknesses\",\"growth_note\",\"last_updated\"]\n",
        "            }\n",
        "        return props\n",
        "\n",
        "    # Build technical skills schema\n",
        "    technical_skills_schema = {}\n",
        "    for domain, ts in profile.get(\"technical_skills\", {}).items():\n",
        "        technical_skills_schema[domain] = {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": ts.get(\"name\", \"\")},\n",
        "                \"subskills\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": build_subskills_schema(ts.get(\"subskills\", {}))\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"name\", \"subskills\"]\n",
        "        }\n",
        "\n",
        "    # Build soft skills schema\n",
        "    soft_skills_schema = {}\n",
        "    for category, ss in profile.get(\"soft_skills\", {}).items():\n",
        "        soft_skills_schema[category] = {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\", \"description\": ss.get(\"name\", \"\")},\n",
        "                \"subskills\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": build_subskills_schema(ss.get(\"subskills\", {}))\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"name\", \"subskills\"]\n",
        "        }\n",
        "\n",
        "    # Full tool schema\n",
        "    tool_schema = {\n",
        "        \"type\": \"function\",\n",
        "\n",
        "        \"function\": {\n",
        "            \"name\": tool_name,\n",
        "            \"description\": (\n",
        "                \"Save or update a candidate profile in MongoDB vector memory. \"\n",
        "                \"Call this whenever the candidate provides new information about their technical or soft skills, projects, or career experience. \"\n",
        "                \"The profile contains static fields (names and descriptions of skills) and dynamic fields \"\n",
        "                \"(evaluation, evidence, growth_note, last_updated) which are populated by the LLM or user after interviews.\"\n",
        "            ),\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"profile\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"description\": \"Complete candidate profile with all skills and subskills.\",\n",
        "                        \"properties\": {\n",
        "                            \"name\": {\"type\": \"string\", \"description\": \"Full name of the candidate\"},\n",
        "                            \"title\": {\"type\": \"string\", \"description\": \"Current role or professional headline\"},\n",
        "                            \"technical_skills\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"description\": \"Dictionary of technical skill domains with subskills\",\n",
        "                                \"properties\": technical_skills_schema\n",
        "                            },\n",
        "                            \"soft_skills\": {\n",
        "                                \"type\": \"object\",\n",
        "                                \"description\": \"Dictionary of soft skill categories with subskills\",\n",
        "                                \"properties\": soft_skills_schema\n",
        "                            }\n",
        "                        },\n",
        "                        \"required\": [\"name\", \"title\", \"technical_skills\", \"soft_skills\"]\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"profile\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return tool_schema\n"
      ],
      "metadata": {
        "id": "8YZXxAjduP1U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Assuming `user` is your UserProfile instance\n",
        "\n",
        "profile_dict = user.model_dump()\n",
        "tool_schema = generate_tool_schema(profile_dict)\n",
        "print(json.dumps(tool_schema, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZq652Cms7UN",
        "outputId": "d79a55a9-5930-4ce5-f80b-99cc8311a73a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"type\": \"function\",\n",
            "  \"function\": {\n",
            "    \"name\": \"save_candidate\",\n",
            "    \"description\": \"Save or update a candidate profile in MongoDB vector memory. Call this whenever the candidate provides new information about their technical or soft skills, projects, or career experience. The profile contains static fields (names and descriptions of skills) and dynamic fields (evaluation, evidence, growth_note, last_updated) which are populated by the LLM or user after interviews.\",\n",
            "    \"parameters\": {\n",
            "      \"type\": \"object\",\n",
            "      \"properties\": {\n",
            "        \"profile\": {\n",
            "          \"type\": \"object\",\n",
            "          \"description\": \"Complete candidate profile with all skills and subskills.\",\n",
            "          \"properties\": {\n",
            "            \"name\": {\n",
            "              \"type\": \"string\",\n",
            "              \"description\": \"Full name of the candidate\"\n",
            "            },\n",
            "            \"title\": {\n",
            "              \"type\": \"string\",\n",
            "              \"description\": \"Current role or professional headline\"\n",
            "            },\n",
            "            \"technical_skills\": {\n",
            "              \"type\": \"object\",\n",
            "              \"description\": \"Dictionary of technical skill domains with subskills\",\n",
            "              \"properties\": {\n",
            "                \"SWE\": {\n",
            "                  \"type\": \"object\",\n",
            "                  \"properties\": {\n",
            "                    \"name\": {\n",
            "                      \"type\": \"string\",\n",
            "                      \"description\": \"SWE\"\n",
            "                    },\n",
            "                    \"subskills\": {\n",
            "                      \"type\": \"object\",\n",
            "                      \"properties\": {\n",
            "                        \"data_structures\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Data Structures\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Understanding of arrays, linked lists, trees, graphs, and their algorithms\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        },\n",
            "                        \"system_design\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"System Design\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Ability to design scalable, maintainable software systems and understand architecture trade-offs\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        },\n",
            "                        \"api_design\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"API Design\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        }\n",
            "                      }\n",
            "                    }\n",
            "                  },\n",
            "                  \"required\": [\n",
            "                    \"name\",\n",
            "                    \"subskills\"\n",
            "                  ]\n",
            "                },\n",
            "                \"ML\": {\n",
            "                  \"type\": \"object\",\n",
            "                  \"properties\": {\n",
            "                    \"name\": {\n",
            "                      \"type\": \"string\",\n",
            "                      \"description\": \"ML\"\n",
            "                    },\n",
            "                    \"subskills\": {\n",
            "                      \"type\": \"object\",\n",
            "                      \"properties\": {\n",
            "                        \"fundamentals\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"ML Fundamentals\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        },\n",
            "                        \"ml_system_design\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"ML System Design\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Designing machine learning pipelines, feature engineering, model deployment, and monitoring\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        },\n",
            "                        \"ai\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"AI / Advanced Topics\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        }\n",
            "                      }\n",
            "                    }\n",
            "                  },\n",
            "                  \"required\": [\n",
            "                    \"name\",\n",
            "                    \"subskills\"\n",
            "                  ]\n",
            "                }\n",
            "              }\n",
            "            },\n",
            "            \"soft_skills\": {\n",
            "              \"type\": \"object\",\n",
            "              \"description\": \"Dictionary of soft skill categories with subskills\",\n",
            "              \"properties\": {\n",
            "                \"Behavioral\": {\n",
            "                  \"type\": \"object\",\n",
            "                  \"properties\": {\n",
            "                    \"name\": {\n",
            "                      \"type\": \"string\",\n",
            "                      \"description\": \"Behavioral\"\n",
            "                    },\n",
            "                    \"subskills\": {\n",
            "                      \"type\": \"object\",\n",
            "                      \"properties\": {\n",
            "                        \"communication\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Communication\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Ability to clearly express ideas, structure answers effectively, and listen actively\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        },\n",
            "                        \"teamwork\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Teamwork\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Collaboration, conflict resolution, and working effectively within a team\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        },\n",
            "                        \"adaptability\": {\n",
            "                          \"type\": \"object\",\n",
            "                          \"properties\": {\n",
            "                            \"name\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Adaptability\"\n",
            "                            },\n",
            "                            \"description\": {\n",
            "                              \"type\": \"string\",\n",
            "                              \"description\": \"Ability to adjust to new challenges, unexpected questions, and changing scenarios\"\n",
            "                            },\n",
            "                            \"growth_note\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"\n",
            "                            },\n",
            "                            \"last_updated\": {\n",
            "                              \"type\": [\n",
            "                                \"string\",\n",
            "                                \"null\"\n",
            "                              ],\n",
            "                              \"description\": \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"\n",
            "                            },\n",
            "                            \"strengths\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"\n",
            "                            },\n",
            "                            \"weaknesses\": {\n",
            "                              \"type\": \"array\",\n",
            "                              \"items\": {\n",
            "                                \"type\": \"string\"\n",
            "                              },\n",
            "                              \"description\": \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"\n",
            "                            }\n",
            "                          },\n",
            "                          \"required\": [\n",
            "                            \"name\",\n",
            "                            \"description\",\n",
            "                            \"strengths\",\n",
            "                            \"weaknesses\",\n",
            "                            \"growth_note\",\n",
            "                            \"last_updated\"\n",
            "                          ]\n",
            "                        }\n",
            "                      }\n",
            "                    }\n",
            "                  },\n",
            "                  \"required\": [\n",
            "                    \"name\",\n",
            "                    \"subskills\"\n",
            "                  ]\n",
            "                }\n",
            "              }\n",
            "            }\n",
            "          },\n",
            "          \"required\": [\n",
            "            \"name\",\n",
            "            \"title\",\n",
            "            \"technical_skills\",\n",
            "            \"soft_skills\"\n",
            "          ]\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"profile\"\n",
            "      ]\n",
            "    }\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools= [tool_schema]\n"
      ],
      "metadata": {
        "id": "AM70VWMc2DW4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recruiter Agent & Memory Manager**"
      ],
      "metadata": {
        "id": "voai1-j5VTwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AIRecruiter:\n",
        "  \"\"\"Recruiter agent\"\"\"\n",
        "  def __init__(self,context_manager:ContextManager, base_url: Optional[str] = None):\n",
        "    self.llm_client=OpenAIClient(\n",
        "            base_url=base_url,\n",
        "            model=\"gpt-oss-20b:free\",\n",
        "            temperature=0.1\n",
        "      )\n",
        "    self.context_manager=context_manager\n",
        "\n",
        "\n",
        "  def run(self):\n",
        "\n",
        "    response = self.llm_client.completion(\n",
        "          messages=self.context_manager.messages,\n",
        "          tools=self.context_manager.tools,\n",
        "\n",
        "    )\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "QanO45_qYXb_"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryManager:\n",
        "  \"\"\"Recruiter agent\"\"\"\n",
        "  def __init__(self,context_manager:ContextManager, base_url: Optional[str] = None):\n",
        "    self.llm_client=OpenAIClient(\n",
        "            base_url=base_url,\n",
        "            model=\"gpt-oss-20b:free\",\n",
        "            temperature=0.1\n",
        "      )\n",
        "    self.context_manager=context_manager\n",
        "\n",
        "\n",
        "  def run(self):\n",
        "\n",
        "    response = self.llm_client.completion(\n",
        "          messages=self.context_manager.messages,\n",
        "          tools=self.context_manager.tools,\n",
        "          tool_choice=\"required\"\n",
        "\n",
        "    )\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "e3fsOvY1TLmu"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02cd3c75"
      },
      "source": [
        "company_profile = {\n",
        "    \"name\": \"rakam.ai\",\n",
        "    \"industry\": \"Product Analytics & Customer Data Platform\",\n",
        "    \"size\": \"11-50 employees\",\n",
        "    \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\n",
        "    \"products\": [\n",
        "        \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\n",
        "        \"Rakam API - Query API for building custom analytics applications\"\n",
        "    ],\n",
        "    \"technologies_used\": [\n",
        "        \"Java\", \"Python\", \"React\", \"PostgreSQL\", \"AWS\", \"Docker\", \"Kubernetes\",\n",
        "        \"Kafka\", \"Redis\", \"Apache Spark\", \"PrestoDB\", \"dbt\", \"Airflow\", \"REST\", \"GraphQL\"\n",
        "    ],\n",
        "    \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\n",
        "}"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eb8606c"
      },
      "source": [
        "job_requirements = {\n",
        "    \"title\": \"GenAI Engineer\",\n",
        "    \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\n",
        "    \"required_skills\": [\n",
        "        \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\n",
        "        \"Hands-on experience with GenAI tools – LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\n",
        "        \"Solid understanding of NLP, data analytics, and statistical modeling.\",\n",
        "        \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\n",
        "        \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\n",
        "    ],\n",
        "    \"nice_to_have_skills\": [\n",
        "        \"Experience with MLOps practices\",\n",
        "        \"Familiarity with vector databases\",\n",
        "        \"Experience with distributed computing frameworks (Spark)\"\n",
        "    ],\n",
        "    \"responsibilities\": [\n",
        "        \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\n",
        "        \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\n",
        "        \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\n",
        "        \"Apply data science techniques to extract insights and optimize AI outcomes.\",\n",
        "        \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\n",
        "        \"Ensure adherence to Responsible AI and data governance best practices.\"\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f7bda18"
      },
      "source": [
        "submitted_resume = \"\"\"\n",
        "Mohamed rami hamrouni - AI Engineer\n",
        " EAexpertise\n",
        " AI Engineer– End Of Studies Internship\n",
        " Tunis, Tunisia\n",
        " Feb 2025– July 2025\n",
        " • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\n",
        "trial forms from voice input, reducing manual entry time by 3 hours per operator per day.\n",
        " • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\n",
        " to maximize contextual accuracy and reasoning reliability.\n",
        " • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\n",
        " • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\n",
        " model routing and fallback logic for cost-performance tradeoffs.\n",
        " • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\n",
        " and prepare for the launch of the startup’s first AI solution.\n",
        " • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\n",
        " Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\n",
        " EAexpertise\n",
        " AI Engineering Intern– Summer Internship\n",
        " Tunis, Tunisia\n",
        " Jul 2024– Aug 2024\n",
        " • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\n",
        " reducing average processing time by 42%.\n",
        " • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\n",
        " • Implemented automated testing and real-time monitoring with LangFuse.\n",
        " • Developed and containerized a ReactJS–Django web application for deploying AI models.\n",
        " Projects\n",
        " Quantitative Trading Developer\n",
        " Freelance\n",
        " Remote / France\n",
        " Oct 2024– Present\n",
        " • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\n",
        " bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\n",
        " optimize performance.\n",
        " • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\n",
        " reducing drawdowns and downtime through a detail-oriented evaluation process.\n",
        " Instruction Fine-tuning of GPT-2 on Medical Data\n",
        " Personal Project\n",
        " Oct 2024– Mar 2025\n",
        " • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\n",
        " regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\n",
        " AI-Powered Research Assistant\n",
        " Personal Project\n",
        " Mar 2024– Jun 2024\n",
        " • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\n",
        " and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\n",
        " workflows to diverse users. [GitHub]\n",
        " Skills\n",
        " Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\n",
        "ing, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\n",
        " & Tools: Docker, Git, GitHub Actions, AWS Lambda\n",
        " Education\n",
        " National School of Computer Science (ENSI)\n",
        " Engineering Degree in Computer Science\n",
        " Tunis, Tunisia\n",
        " Sept 2022– Sept 2025\n",
        " • Specialization: Artificial Intelligence\n",
        "Preparatory Institute for Engineering Studies of Tunis (IPEIT)\n",
        " Mathematics–Physics Track\n",
        " • National Entrance Exam Ranking: 380 / 2000\n",
        " Honors and Awards\n",
        " • 1st Prize, Ensi Competitive Programming Challenge\n",
        " • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\n",
        " Languages\n",
        " Tunis, Tunisia\n",
        " Sept 2020– June 2022\n",
        " December 2023\n",
        " April 2024\n",
        " Arabic: Native French: Fluent English: Fluen\n",
        "\"\"\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profile = {\n",
        "    \"name\": \"Mohamed Rami Hamrouni\",\n",
        "    \"title\": \"AI Engineer\",\n",
        "    \"technical_skills\": {\n",
        "        \"SWE\": {\n",
        "            \"name\": \"SWE\",\n",
        "            \"subskills\": {\n",
        "                \"data_structures\": {\n",
        "                    \"name\": \"Data Structures\",\n",
        "                    \"description\": \"Understanding of arrays, linked lists, trees, graphs, and their algorithms\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                },\n",
        "                \"system_design\": {\n",
        "                    \"name\": \"System Design\",\n",
        "                    \"description\": \"Ability to design scalable, maintainable software systems and understand architecture trade-offs\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                },\n",
        "                \"api_design\": {\n",
        "                    \"name\": \"API Design\",\n",
        "                    \"description\": \"Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"ML\": {\n",
        "            \"name\": \"ML\",\n",
        "            \"subskills\": {\n",
        "                \"fundamentals\": {\n",
        "                    \"name\": \"ML Fundamentals\",\n",
        "                    \"description\": \"Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                },\n",
        "                \"ml_system_design\": {\n",
        "                    \"name\": \"ML System Design\",\n",
        "                    \"description\": \"Designing machine learning pipelines, feature engineering, model deployment, and monitoring\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                },\n",
        "                \"ai\": {\n",
        "                    \"name\": \"AI / Advanced Topics\",\n",
        "                    \"description\": \"Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"soft_skills\": {\n",
        "        \"Behavioral\": {\n",
        "            \"name\": \"Behavioral\",\n",
        "            \"subskills\": {\n",
        "                \"communication\": {\n",
        "                    \"name\": \"Communication\",\n",
        "                    \"description\": \"Ability to clearly express ideas, structure answers effectively, and listen actively\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                },\n",
        "                \"teamwork\": {\n",
        "                    \"name\": \"Teamwork\",\n",
        "                    \"description\": \"Collaboration, conflict resolution, and working effectively within a team\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                },\n",
        "                \"adaptability\": {\n",
        "                    \"name\": \"Adaptability\",\n",
        "                    \"description\": \"Ability to adjust to new challenges, unexpected questions, and changing scenarios\",\n",
        "                    \"strengths\": [],\n",
        "                    \"weaknesses\": [],\n",
        "                    \"growth_note\": None,\n",
        "                    \"last_updated\": None\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "save_candidate(user_profile,\"mohamed_rami\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "v9PD_PiniXiu",
        "outputId": "50b40aaf-c51f-4a74-8eca-06ce51c25f00"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Profile ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Candidate Mohamed Rami Hamrouni saved'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user = get_user(\"mohamed_rami\")\n",
        "\n"
      ],
      "metadata": {
        "id": "je4xZ-jACjeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bee74dc-5622-41eb-e5f3-227961de0040"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item(namespace=['mohamed_rami'], key='profile', value={'content': '{\\n  \"name\": \"Mohamed Rami Hamrouni\",\\n  \"title\": \"AI Engineer\",\\n  \"technical_skills\": {\\n    \"SWE\": {\\n      \"name\": \"SWE\",\\n      \"subskills\": {\\n        \"data_structures\": {\\n          \"name\": \"Data Structures\",\\n          \"description\": \"Understanding of arrays, linked lists, trees, graphs, and their algorithms\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"system_design\": {\\n          \"name\": \"System Design\",\\n          \"description\": \"Ability to design scalable, maintainable software systems and understand architecture trade-offs\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"api_design\": {\\n          \"name\": \"API Design\",\\n          \"description\": \"Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        }\\n      }\\n    },\\n    \"ML\": {\\n      \"name\": \"ML\",\\n      \"subskills\": {\\n        \"fundamentals\": {\\n          \"name\": \"ML Fundamentals\",\\n          \"description\": \"Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"ml_system_design\": {\\n          \"name\": \"ML System Design\",\\n          \"description\": \"Designing machine learning pipelines, feature engineering, model deployment, and monitoring\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"ai\": {\\n          \"name\": \"AI / Advanced Topics\",\\n          \"description\": \"Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        }\\n      }\\n    }\\n  },\\n  \"soft_skills\": {\\n    \"Behavioral\": {\\n      \"name\": \"Behavioral\",\\n      \"subskills\": {\\n        \"communication\": {\\n          \"name\": \"Communication\",\\n          \"description\": \"Ability to clearly express ideas, structure answers effectively, and listen actively\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"teamwork\": {\\n          \"name\": \"Teamwork\",\\n          \"description\": \"Collaboration, conflict resolution, and working effectively within a team\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"adaptability\": {\\n          \"name\": \"Adaptability\",\\n          \"description\": \"Ability to adjust to new challenges, unexpected questions, and changing scenarios\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        }\\n      }\\n    }\\n  }\\n}'}, created_at='2025-10-31T17:44:54.725000', updated_at='2025-11-03T19:49:22.695000')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def json_serial(obj):\n",
        "    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n",
        "    if isinstance(obj, datetime):\n",
        "        return obj.isoformat()\n",
        "    raise TypeError (\"Type %s not serializable\" % type(obj))\n",
        "\n",
        "profile_str = json.dumps(user.model_dump(), indent=2, default=json_serial)"
      ],
      "metadata": {
        "id": "4rY37Ng6Cjvr"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "NeeV9L8mCx9R",
        "outputId": "a4aaf464-7722-4c39-a094-8ab2ecf403fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n  \"name\": \"Mohamed Rami Hamrouni\",\\n  \"title\": \"AI Engineer\",\\n  \"technical_skills\": {\\n    \"SWE\": {\\n      \"name\": \"SWE\",\\n      \"subskills\": {\\n        \"data_structures\": {\\n          \"name\": \"Data Structures\",\\n          \"description\": \"Understanding of arrays, linked lists, trees, graphs, and their algorithms\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"system_design\": {\\n          \"name\": \"System Design\",\\n          \"description\": \"Ability to design scalable, maintainable software systems and understand architecture trade-offs\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"api_design\": {\\n          \"name\": \"API Design\",\\n          \"description\": \"Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        }\\n      }\\n    },\\n    \"ML\": {\\n      \"name\": \"ML\",\\n      \"subskills\": {\\n        \"fundamentals\": {\\n          \"name\": \"ML Fundamentals\",\\n          \"description\": \"Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"ml_system_design\": {\\n          \"name\": \"ML System Design\",\\n          \"description\": \"Designing machine learning pipelines, feature engineering, model deployment, and monitoring\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"ai\": {\\n          \"name\": \"AI / Advanced Topics\",\\n          \"description\": \"Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        }\\n      }\\n    }\\n  },\\n  \"soft_skills\": {\\n    \"Behavioral\": {\\n      \"name\": \"Behavioral\",\\n      \"subskills\": {\\n        \"communication\": {\\n          \"name\": \"Communication\",\\n          \"description\": \"Ability to clearly express ideas, structure answers effectively, and listen actively\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"teamwork\": {\\n          \"name\": \"Teamwork\",\\n          \"description\": \"Collaboration, conflict resolution, and working effectively within a team\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        },\\n        \"adaptability\": {\\n          \"name\": \"Adaptability\",\\n          \"description\": \"Ability to adjust to new challenges, unexpected questions, and changing scenarios\",\\n          \"strengths\": [],\\n          \"weaknesses\": [],\\n          \"growth_note\": null,\\n          \"last_updated\": null\\n        }\\n      }\\n    }\\n  }\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B77U4S1E85_2",
        "outputId": "a0350b3b-0b4b-4a5e-dc3f-c8bef68265ab"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'type': 'function',\n",
              " 'function': {'name': 'save_candidate',\n",
              "  'description': 'Save or update a candidate profile in MongoDB vector memory. Call this whenever the candidate provides new information about their technical or soft skills, projects, or career experience. The profile contains static fields (names and descriptions of skills) and dynamic fields (evaluation, evidence, growth_note, last_updated) which are populated by the LLM or user after interviews.',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'profile': {'type': 'object',\n",
              "     'description': 'Complete candidate profile with all skills and subskills.',\n",
              "     'properties': {'name': {'type': 'string',\n",
              "       'description': 'Full name of the candidate'},\n",
              "      'title': {'type': 'string',\n",
              "       'description': 'Current role or professional headline'},\n",
              "      'technical_skills': {'type': 'object',\n",
              "       'description': 'Dictionary of technical skill domains with subskills',\n",
              "       'properties': {'SWE': {'type': 'object',\n",
              "         'properties': {'name': {'type': 'string', 'description': 'SWE'},\n",
              "          'subskills': {'type': 'object',\n",
              "           'properties': {'data_structures': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'Data Structures'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Understanding of arrays, linked lists, trees, graphs, and their algorithms'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']},\n",
              "            'system_design': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'System Design'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Ability to design scalable, maintainable software systems and understand architecture trade-offs'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']},\n",
              "            'api_design': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'API Design'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']}}}},\n",
              "         'required': ['name', 'subskills']},\n",
              "        'ML': {'type': 'object',\n",
              "         'properties': {'name': {'type': 'string', 'description': 'ML'},\n",
              "          'subskills': {'type': 'object',\n",
              "           'properties': {'fundamentals': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'ML Fundamentals'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']},\n",
              "            'ml_system_design': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'ML System Design'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Designing machine learning pipelines, feature engineering, model deployment, and monitoring'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']},\n",
              "            'ai': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'AI / Advanced Topics'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']}}}},\n",
              "         'required': ['name', 'subskills']}}},\n",
              "      'soft_skills': {'type': 'object',\n",
              "       'description': 'Dictionary of soft skill categories with subskills',\n",
              "       'properties': {'Behavioral': {'type': 'object',\n",
              "         'properties': {'name': {'type': 'string',\n",
              "           'description': 'Behavioral'},\n",
              "          'subskills': {'type': 'object',\n",
              "           'properties': {'communication': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'Communication'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Ability to clearly express ideas, structure answers effectively, and listen actively'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']},\n",
              "            'teamwork': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'Teamwork'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Collaboration, conflict resolution, and working effectively within a team'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']},\n",
              "            'adaptability': {'type': 'object',\n",
              "             'properties': {'name': {'type': 'string',\n",
              "               'description': 'Adaptability'},\n",
              "              'description': {'type': 'string',\n",
              "               'description': 'Ability to adjust to new challenges, unexpected questions, and changing scenarios'},\n",
              "              'growth_note': {'type': ['string', 'null'],\n",
              "               'description': \"Actionable suggestions, recommendations, or next steps to improve performance in this subskill. Examples: 'Explore Kubernetes for orchestration' or 'Practice advanced hyperparameter tuning'. Null if no improvement note is available.\"},\n",
              "              'last_updated': {'type': ['string', 'null'],\n",
              "               'description': \"ISO 8601 formatted timestamp (e.g., '2025-10-29T12:00:00Z') representing when this subskill was last evaluated or modified. Null if never updated.\"},\n",
              "              'strengths': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of key strong points, achievements, or evidence of proficiency for this subskill. Each item should be a short, clear statement (e.g., 'Designed scalable API gateway with CI/CD automation').\"},\n",
              "              'weaknesses': {'type': 'array',\n",
              "               'items': {'type': 'string'},\n",
              "               'description': \"A list of areas needing improvement or common pitfalls related to this subskill. Each item should be a short statement describing a limitation or growth opportunity (e.g., 'Limited experience with Kubernetes scaling').\"}},\n",
              "             'required': ['name',\n",
              "              'description',\n",
              "              'strengths',\n",
              "              'weaknesses',\n",
              "              'growth_note',\n",
              "              'last_updated']}}}},\n",
              "         'required': ['name', 'subskills']}}}},\n",
              "     'required': ['name', 'title', 'technical_skills', 'soft_skills']}},\n",
              "   'required': ['profile']}}}"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RwWDSf4EC8kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph constraction**"
      ],
      "metadata": {
        "id": "DlkaSBgbE9WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, TypedDict, List,Annotated\n",
        "import operator\n",
        "\n",
        "# Define your state\n",
        "class State(TypedDict):\n",
        "    ai_recruiter_messages:  Annotated[list, operator.add]\n",
        "    ai_recruiter_tools : List\n",
        "    memory_manager_messages: Annotated[list, operator.add]\n",
        "    memory_manager_tools : List\n",
        "    update_memory: bool\n"
      ],
      "metadata": {
        "id": "08s0fpVPE_1r"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w764VIdgH-uI"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ai_recruiter_node(state: State):\n",
        "    print(\"AI Recruiter Node\")\n",
        "    context_manager = ContextManager(messages=state[\"ai_recruiter_messages\"], tools=state[\"ai_recruiter_tools\"])\n",
        "    ai_recruiter = AIRecruiter(context_manager=context_manager,base_url=\"https://openrouter.ai/api/v1\")\n",
        "    response = ai_recruiter.run()\n",
        "    context_manager.add_message(role=\"assistant\", content=response.content)\n",
        "    state[\"ai_recruiter_messages\"]=context_manager.messages\n",
        "\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "kvUIqxn1JTP8"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_manager_node(state: State):\n",
        "    if not state[\"update_memory\"]:\n",
        "      return\n",
        "    context_manager = ContextManager(messages=state[\"memory_manager_messages\"], tools=state[\"memory_manager_tools\"])\n",
        "    memory_manager = MemoryManager(context_manager=context_manager,base_url=\"https://openrouter.ai/api/v1\")\n",
        "    response = memory_manager.run()\n",
        "    if response.tool_calls :\n",
        "      context_manager.add_message(role=\"assistant\",content=response.tool_calls[:1])\n",
        "      state[\"memory_manager_messages\"]=context_manager.messages\n",
        "    return  {\"memory_manager_messages\":context_manager.messages}"
      ],
      "metadata": {
        "id": "ulRt8tFRRwuQ"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_tool(state:State):\n",
        "  if not state[\"update_memory\"]:\n",
        "      return\n",
        "  print(\"Executing Tool\")\n",
        "  recruiter_response= state[\"memory_manager_messages\"][-1]\n",
        "  for tool_call in recruiter_response[\"tool_calls\"][:1]:\n",
        "\n",
        "      try:\n",
        "          function_name = tool_call.function.name\n",
        "          arguments = json.loads(tool_call.function.arguments)\n",
        "      except:\n",
        "          print(f\"Error parsing arguments: {tool_call.function.arguments}\")\n",
        "          continue\n",
        "      if function_name == \"save_candidate\":\n",
        "          try:\n",
        "              arguments['user_id']=user_id\n",
        "              save_candidate(**arguments)\n",
        "\n",
        "              state[\"memory_manager_messages\"].append({\n",
        "                  \"role\": \"tool\",\n",
        "                  \"tool_call_id\": tool_call.id,\n",
        "                  \"content\": json.dumps({\n",
        "                      \"status\": \"success\",\n",
        "                      \"message\": \"Candidate saved successfully!\",\n",
        "                      \"result\": \"Success\"\n",
        "                  })\n",
        "              })\n",
        "\n",
        "              print(\"Candidate saved successfully!\")\n",
        "          except Exception as e:\n",
        "              state[\"memory_manager_messages\"].append({\n",
        "                  \"type\": \"tool\",\n",
        "                  \"tool_call_id\": tool_call.id,  # link to tool call\n",
        "                  \"content\": json.dumps({\n",
        "                      \"status\": \"error\",\n",
        "                      \"message\": \"Error saving candidate\",\n",
        "                      \"result\": \"Error\"\n",
        "                  })\n",
        "              })\n",
        "              print(f\"Error saving candidate: {e}\")\n",
        "  return {\"memory_manager_messages\":context_manager.messages}\n"
      ],
      "metadata": {
        "id": "iKs1iR17jpFp"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import  StateGraph,START,END\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"execute_tool\", execute_tool)\n",
        "graph.add_node(\"ai_recruiter_node\", ai_recruiter_node)\n",
        "graph.add_node(\"memory_manager_node\", memory_manager_node)\n",
        "\n",
        "graph.add_edge(START, \"ai_recruiter_node\")\n",
        "graph.add_edge(START, \"memory_manager_node\")\n",
        "graph.add_edge(\"memory_manager_node\", \"execute_tool\")\n",
        "graph.add_edge(\"ai_recruiter_node\", END)\n",
        "graph.add_edge(\"execute_tool\", END)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aMD8Dxgnf_p",
        "outputId": "9877f99f-2e21-4779-d54d-4c678d8e1de0"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d61360c50d0>"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app=graph.compile()"
      ],
      "metadata": {
        "id": "aGaDhedwK49d"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "6xpbUUp9okmk",
        "outputId": "c5b308e9-dc76-41d1-d8e4-276eab8a22cd"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7d612deeaed0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
        "user_id=\"mohamed_rami\"\n",
        "namespaced_thread_id = f\"{user_id}-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
        "config = {\"configurable\": {\"thread_id\": namespaced_thread_id}}\n",
        "with MongoDBSaver.from_conn_string(\n",
        "        conn_string=MONGODB_URI,\n",
        "        db_name=\"recruiter_ai_companion\",\n",
        "        collection_name=\"checkpoints\",\n",
        "        namespace=(user_id,)\n",
        "        ) as checkpointer:\n",
        "        app = graph.compile(checkpointer=checkpointer)\n",
        "\n",
        "\n",
        "        RECRUITER_CONTEXT = f\"\"\"\n",
        "        Submitted Resume : {submitted_resume}\n",
        "        Company Profile : {json.dumps(company_profile, indent=2)}\n",
        "        Job Requirements : {json.dumps(job_requirements, indent=2)}\n",
        "        \"\"\"\n",
        "        AI_RECRUITER_PROMPT = create_expanded_context(\n",
        "          base_prompt=f\"\"\"You are conducting an interview with a candidate.\n",
        "          {RECRUITER_CONTEXT}\n",
        "          \"\"\",\n",
        "          role=\"Recruiter\",\n",
        "          audience=\"Candidate\",\n",
        "          tone=\"Professional and friendly\",\n",
        "          constraints=[\"Start with greeting and introducing the company overview briefly\",\n",
        "                        \"Do not ask personal questions\",\n",
        "                       \"Ask one question at a time and adapt based on the candidate’s responses.\",\n",
        "                       \"Questions should be related to candidate projects or company required skills\",\n",
        "                       \"Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.\",\n",
        "                       ]\n",
        "      )\n",
        "        MEMORY_MANAGER_PROMPT=create_expanded_context(\n",
        "            base_prompt=f\"You are a memory manager responsible for keeping user profile up to date based on current state of conversation\",\n",
        "            role=\"Memory Manager\",\n",
        "            constraints=[\"When you detect any weakness or strength in any subskill update user profile accordicaly\",\n",
        "                         \"The update should be detailed\"\n",
        "                       ]\n",
        "        )\n",
        "\n",
        "        ai_recuiter_messages = [\n",
        "            {\"role\": \"system\", \"content\": AI_RECRUITER_PROMPT}\n",
        "\n",
        "        ]\n",
        "        memory_manger_messages=[\n",
        "            {\"role\": \"system\", \"content\": MEMORY_MANAGER_PROMPT}\n",
        "\n",
        "        ]\n",
        "        memory_manager_tools=[tool_schema]\n",
        "\n",
        "\n",
        "\n",
        "        state = {\"ai_recruiter_messages\": ai_recuiter_messages,\"ai_recruiter_tools\":None,\"memory_manager_messages\":memory_manger_messages,\"memory_manager_tools\":memory_manager_tools,\"update_memory\":False}\n",
        "        config = {\"configurable\": {\"thread_id\": namespaced_thread_id}}\n",
        "        result_state = app.invoke(state,config=config)\n",
        "        last_message = result_state[\"ai_recruiter_messages\"][-1]\n",
        "\n",
        "        if isinstance(last_message, dict):\n",
        "          print(\"AI Recruiter:\", last_message.get(\"content\", \"\"))\n",
        "        else:\n",
        "          print(\"AI Recruiter:\", last_message.content)\n",
        "        while True:\n",
        "          user_input = input(\"You: \").strip()\n",
        "          if user_input.lower() in {\"exit\", \"quit\"}:\n",
        "              print(\"AI Recruiter: Goodbye!\")\n",
        "              break\n",
        "          result_state[\"ai_recruiter_messages\"].append({\"role\": \"user\", \"content\": user_input})\n",
        "          if len(state[\"ai_recruiter_messages\"])>=5:\n",
        "            result_state[\"update_memory\"]=True\n",
        "            conversation_string=result_state[\"ai_recruiter_messages\"][-4:]\n",
        "            print(\"Updating memory...\")\n",
        "            print(f\"Current conversation state:{conversation_string}\")\n",
        "            result_state[\"memory_manager_messages\"].append(\n",
        "                {\"role\":\"user\",\"content\":f\"Current conversation state: {str(conversation_string)}\"}\n",
        "            )\n",
        "\n",
        "          result_state = app.invoke(result_state,config=config)\n",
        "          last_message = result_state[\"ai_recruiter_messages\"][-1]\n",
        "          if isinstance(last_message, dict):\n",
        "            print(\"AI Recruiter:\", last_message.get(\"content\", \"\"))\n",
        "          else:\n",
        "            print(\"AI Recruiter:\", last_message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "ANB9OJOXQXq2",
        "outputId": "c8e54f7f-61c1-4c4b-e218-03be4cbd931a"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Recruiter Node\n",
            "AI Recruiter: Hi Mohamed,  \n",
            "\n",
            "Welcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\n",
            "\n",
            "I’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?\n",
            "You: Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.\n",
            "AI Recruiter Node\n",
            "AI Recruiter: That’s a great example—thanks for sharing the details.  \n",
            "Since we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?\n",
            "You: Absolutely! For the GPT‑2 fine-tuning on the medical dataset, I used Hugging Face Transformers with PyTorch. The first step was data preprocessing: cleaning text, normalizing terminology, deduplicating entries, and splitting the dataset into training, validation, and test sets to ensure reliable evaluation.  During training, I fine-tuned the model with small learning rates and early stopping to avoid overfitting, while monitoring loss on the validation set. Post-training, I evaluated the model using semantic similarity scores between generated outputs and reference text, along with qualitative checks to ensure the medical information was accurate and the tone consistent.  This approach allowed the model to generate contextually accurate and reliable medical responses while maintaining generalization, which was critical given the sensitivity of the domain\n",
            "AI Recruiter Node\n",
            "AI Recruiter: That’s a solid approach—thanks for outlining the process.  \n",
            "At **rakam.ai** we deploy models in a highly automated, container‑based environment on AWS. Could you walk me through a recent deployment you’ve set up (e.g., using Docker, GitHub Actions, or ECS), including how you handled model versioning, scaling, and monitoring for latency or accuracy?\n",
            "You: Sure! In my recent deployment, I containerized each agent in the multi-agent system using Docker and deployed them on AWS ECS. For automated releases, I set up a CI/CD pipeline with GitHub Actions that built the images, ran tests, and deployed updates to a staging environment before production.  For model versioning, each Docker image was tagged with the model version and Git commit hash, so we could easily roll back if needed. Scaling was handled with ECS task autoscaling based on CPU and memory usage, allowing the system to handle fluctuating workloads.  For monitoring, I integrated CloudWatch to track latency, error rates, and CPU/memory metrics, and added simple logging to detect anomalies in model outputs. This setup ensured smooth, reliable deployment while maintaining visibility into performance and operational health\n",
            "AI Recruiter Node\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': 'This endpoint\\'s maximum context length is 131072 tokens. However, you requested about 131331 tokens (131331 of text input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.', 'code': 400, 'metadata': {'provider_name': None}}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-240201204.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m             )\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m           \u001b[0mresult_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m           \u001b[0mlast_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ai_recruiter_messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInterrupt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3094\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   3095\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/main.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2677\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch_cached_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_writes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   2680\u001b[0m                         \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# panic on failure or timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             _panic_or_proceed(\n\u001b[0m\u001b[1;32m    259\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mpanic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_runner.py\u001b[0m in \u001b[0;36m_panic_or_proceed\u001b[0;34m(futs, timeout_exc_cls, panic)\u001b[0m\n\u001b[1;32m    518\u001b[0m                     \u001b[0minterrupts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mfut\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSKIP_RERAISE_SET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;31m# raise combined interrupts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minterrupts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_executor.py\u001b[0m in \u001b[0;36mdone\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGraphBubbleUp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# This exception is an interruption signal, not an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/pregel/_retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m                     \u001b[0;31m# run in context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m                         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langgraph/_internal/_runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3419505225.py\u001b[0m in \u001b[0;36mai_recruiter_node\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ai_recruiter_messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ai_recruiter_tools\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mai_recruiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAIRecruiter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://openrouter.ai/api/v1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai_recruiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcontext_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ai_recruiter_messages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-374013716.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     response = self.llm_client.completion(\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-340302676.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, messages, tools, tool_choice)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Received response from OpenAI completion.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'This endpoint\\'s maximum context length is 131072 tokens. However, you requested about 131331 tokens (131331 of text input). Please reduce the length of either one, or use the \"middle-out\" transform to compress your prompt automatically.', 'code': 400, 'metadata': {'provider_name': None}}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q"
      ],
      "metadata": {
        "id": "PbyJQ1e8dcJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tmQZmOdQep-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_state[\"ai_recruiter_messages\"][:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_7j80I3TobO",
        "outputId": "e24d7045-5354-4b71-a844-87926eae83f7"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Absolutely! For the GPT‑2 fine-tuning on the medical dataset, I used Hugging Face Transformers with PyTorch. The first step was data preprocessing: cleaning text, normalizing terminology, deduplicating entries, and splitting the dataset into training, validation, and test sets to ensure reliable evaluation.  During training, I fine-tuned the model with small learning rates and early stopping to avoid overfitting, while monitoring loss on the validation set. Post-training, I evaluated the model using semantic similarity scores between generated outputs and reference text, along with qualitative checks to ensure the medical information was accurate and the tone consistent.  This approach allowed the model to generate contextually accurate and reliable medical responses while maintaining generalization, which was critical given the sensitivity of the domain'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a solid approach—thanks for outlining the process.  \\nAt **rakam.ai** we deploy models in a highly automated, container‑based environment on AWS. Could you walk me through a recent deployment you’ve set up (e.g., using Docker, GitHub Actions, or ECS), including how you handled model versioning, scaling, and monitoring for latency or accuracy?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'system',\n",
              "  'content': 'You are Recruiter.\\n\\nYou are conducting an interview with a candidate.\\n          \\n        Submitted Resume : \\nMohamed rami hamrouni - AI Engineer\\n EAexpertise\\n AI Engineer– End Of Studies Internship\\n Tunis, Tunisia\\n Feb 2025– July 2025\\n • Designed and implemented an agentic multi-agent architecture with function calling to autonomously fill indus\\ntrial forms from voice input, reducing manual entry time by 3 hours per operator per day.\\n • Conducted prompt optimization and evaluation experiments (CoT, few-shot, retrieval-augmented prompting)\\n to maximize contextual accuracy and reasoning reliability.\\n • Built evaluation pipelines with LangFuse to measure LLM latency, accuracy, and cost across providers.\\n • Developed a provider-agnostic orchestration layer supporting OpenAI, Mistral, and LLaMA, enabling dynamic\\n model routing and fallback logic for cost-performance tradeoffs.\\n • Worked under the mentorship of the CEO (Solution Architect) and Manager to build the technical foundation\\n and prepare for the launch of the startup’s first AI solution.\\n • Deployed and scaled agentic GenAI service on AWS ECS, leveraging Dockerized microservices and GitHub\\n Actions CI/CD for automated, reliable releases with integrated unit and performance testing pipelines.\\n EAexpertise\\n AI Engineering Intern– Summer Internship\\n Tunis, Tunisia\\n Jul 2024– Aug 2024\\n • Built a LangGraph-based multi-agent system to analyze and extract key data from over 1,000 RFP documents,\\n reducing average processing time by 42%.\\n • Integrated semantic vector search (cosine and dot-product similarity) to match RFPs with company profiles.\\n • Implemented automated testing and real-time monitoring with LangFuse.\\n • Developed and containerized a ReactJS–Django web application for deploying AI models.\\n Projects\\n Quantitative Trading Developer\\n Freelance\\n Remote / France\\n Oct 2024– Present\\n • Built and iterated on algorithmic trading strategies on QuantConnect LEAN with minute-level data, including\\n bull-flag pattern detection (MACD + ATR) and walk-forward analysis, applying a research-driven mindset to\\n optimize performance.\\n • Developed second-level risk management with dynamic trailing stops and live signal monitoring via Python,\\n reducing drawdowns and downtime through a detail-oriented evaluation process.\\n Instruction Fine-tuning of GPT-2 on Medical Data\\n Personal Project\\n Oct 2024– Mar 2025\\n • Fine-tuned GPT-2 on curated medical data in Alpaca format using PyTorch, optimizing hyperparameters and\\n regularization to improve accuracy and generalization while communicating results effectively. [GitHub]\\n AI-Powered Research Assistant\\n Personal Project\\n Mar 2024– Jun 2024\\n • Built a Retrieval-Augmented Generation (RAG) system with LangChain & Streamlit, integrating Gemini 1.5\\n and semantic vector search to reduce research review time by 35%, showcasing clear communication of complex\\n workflows to diverse users. [GitHub]\\n Skills\\n Languages: Python, TypeScript, SQL | AI & ML:LangChain, LangGraph, LangFuse, RAG,PromptEngineer\\ning, Context Engineering; Fine-tuning, Dataset Evaluation | Web Tech: Next.js, Node.js, FastAPI | DevOps\\n & Tools: Docker, Git, GitHub Actions, AWS Lambda\\n Education\\n National School of Computer Science (ENSI)\\n Engineering Degree in Computer Science\\n Tunis, Tunisia\\n Sept 2022– Sept 2025\\n • Specialization: Artificial Intelligence\\nPreparatory Institute for Engineering Studies of Tunis (IPEIT)\\n Mathematics–Physics Track\\n • National Entrance Exam Ranking: 380 / 2000\\n Honors and Awards\\n • 1st Prize, Ensi Competitive Programming Challenge\\n • 2nd Prize, 40th Anniversary ENSI Competitive Programming Challenge\\n Languages\\n Tunis, Tunisia\\n Sept 2020– June 2022\\n December 2023\\n April 2024\\n Arabic: Native French: Fluent English: Fluen\\n\\n        Company Profile : {\\n  \"name\": \"rakam.ai\",\\n  \"industry\": \"Product Analytics & Customer Data Platform\",\\n  \"size\": \"11-50 employees\",\\n  \"culture\": \"Data-driven, remote-first, engineering excellence, customer-obsessed, and highly collaborative.\",\\n  \"products\": [\\n    \"rakam - Real-time Customer Data Platform (CDP) & Product Analytics Platform\",\\n    \"Rakam API - Query API for building custom analytics applications\"\\n  ],\\n  \"technologies_used\": [\\n    \"Java\",\\n    \"Python\",\\n    \"React\",\\n    \"PostgreSQL\",\\n    \"AWS\",\\n    \"Docker\",\\n    \"Kubernetes\",\\n    \"Kafka\",\\n    \"Redis\",\\n    \"Apache Spark\",\\n    \"PrestoDB\",\\n    \"dbt\",\\n    \"Airflow\",\\n    \"REST\",\\n    \"GraphQL\"\\n  ],\\n  \"mission\": \"To make it effortless for companies to collect, unify, and analyze their customer data to build better products and drive growth.\"\\n}\\n        Job Requirements : {\\n  \"title\": \"GenAI Engineer\",\\n  \"description\": \"We are seeking a GenAI Engineer with a strong background in data science and machine learning to design, develop, and deploy innovative AI solutions. The role focuses on building and fine-tuning LLMs, developing RAG pipelines, and transforming data into intelligent automation and decision-support systems.\",\\n  \"required_skills\": [\\n    \"Strong proficiency in Python, SQL, and ML/DL frameworks (TensorFlow, PyTorch).\",\\n    \"Hands-on experience with GenAI tools \\\\u2013 LangChain, Hugging Face, LlamaIndex, OpenAI APIs.\",\\n    \"Solid understanding of NLP, data analytics, and statistical modeling.\",\\n    \"Experience with cloud platforms such as Azure, AWS, or GCP.\",\\n    \"Knowledge of model deployment, LLM fine-tuning, and prompt engineering.\"\\n  ],\\n  \"nice_to_have_skills\": [\\n    \"Experience with MLOps practices\",\\n    \"Familiarity with vector databases\",\\n    \"Experience with distributed computing frameworks (Spark)\"\\n  ],\\n  \"responsibilities\": [\\n    \"Design, build, and deploy GenAI and ML models for scalable business applications.\",\\n    \"Fine-tune and integrate LLMs using frameworks like LangChain, LlamaIndex, or Hugging Face.\",\\n    \"Develop and maintain data pipelines and ensure model performance and accuracy.\",\\n    \"Apply data science techniques to extract insights and optimize AI outcomes.\",\\n    \"Collaborate with cross-functional teams to identify and implement AI-driven solutions.\",\\n    \"Ensure adherence to Responsible AI and data governance best practices.\"\\n  ]\\n}\\n        \\n          \\n\\nYour response should be suitable for Candidate.\\n\\nUse a Professional and friendly tone in your response.\\n\\nRequirements:\\n\\n- Start with greeting and introducing the company overview briefly\\n\\n- Do not ask personal questions\\n\\n- Ask one question at a time and adapt based on the candidate’s responses.\\n\\n- Questions should be related to candidate projects or company required skills\\n\\n- Always speak and act exactly like a recruiter. No generic headers, recaps, or internal instructions in your output.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'Hi Mohamed,  \\n\\nWelcome! I’m excited to learn more about your background. At **rakam.ai** we’re building a real‑time Customer Data Platform that helps companies unify and analyze their customer data to drive product growth. Our team is data‑driven, remote‑first, and focused on engineering excellence and customer obsession.\\n\\nI’d love to start by hearing about your experience building Retrieval‑Augmented Generation (RAG) systems. Could you walk me through one of the RAG projects you’ve worked on, highlighting the architecture, the tools you used, and the impact it had?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! One RAG project I worked on involved building an AI assistant that could answer domain-specific questions using both structured and unstructured data. The architecture had three main components: a retriever, a vector store, and a generator. I used LangChain to orchestrate the workflow, FAISS and Pinecone for vector storage, and OpenAI GPT models for generation.  The pipeline worked by first embedding incoming queries, retrieving the most relevant documents from the vector store, and then passing them to the LLM to generate accurate, context-aware answers. We also implemented metadata filtering and caching to improve retrieval speed and precision.  The impact was significant: we reduced average query response errors by around 20–25% and improved latency for real-time responses, making the system reliable enough to support production usage for multiple internal applications.'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a great example—thanks for sharing the details.  \\nSince we’re looking for someone who can fine‑tune and deploy LLMs at scale, could you describe your experience fine‑tuning GPT‑2 on the medical dataset you mentioned? Specifically, what framework you used, how you handled data preprocessing, and what metrics you tracked to evaluate the fine‑tuned model’s performance?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Absolutely! For the GPT‑2 fine-tuning on the medical dataset, I used Hugging Face Transformers with PyTorch. The first step was data preprocessing: cleaning text, normalizing terminology, deduplicating entries, and splitting the dataset into training, validation, and test sets to ensure reliable evaluation.  During training, I fine-tuned the model with small learning rates and early stopping to avoid overfitting, while monitoring loss on the validation set. Post-training, I evaluated the model using semantic similarity scores between generated outputs and reference text, along with qualitative checks to ensure the medical information was accurate and the tone consistent.  This approach allowed the model to generate contextually accurate and reliable medical responses while maintaining generalization, which was critical given the sensitivity of the domain'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'That’s a solid approach—thanks for outlining the process.  \\nAt **rakam.ai** we deploy models in a highly automated, container‑based environment on AWS. Could you walk me through a recent deployment you’ve set up (e.g., using Docker, GitHub Actions, or ECS), including how you handled model versioning, scaling, and monitoring for latency or accuracy?'},\n",
              " {'role': 'user',\n",
              "  'content': 'Sure! In my recent deployment, I containerized each agent in the multi-agent system using Docker and deployed them on AWS ECS. For automated releases, I set up a CI/CD pipeline with GitHub Actions that built the images, ran tests, and deployed updates to a staging environment before production.  For model versioning, each Docker image was tagged with the model version and Git commit hash, so we could easily roll back if needed. Scaling was handled with ECS task autoscaling based on CPU and memory usage, allowing the system to handle fluctuating workloads.  For monitoring, I integrated CloudWatch to track latency, error rates, and CPU/memory metrics, and added simple logging to detect anomalies in model outputs. This setup ensured smooth, reliable deployment while maintaining visibility into performance and operational health'}]"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Verify the state graph with a demo\n",
        "#TODO: Langfuse integration for monitoring\n",
        "#TODO: Procedural Memory\n",
        "#TODO: the agent should adapt to the weaknesses of the user to see any progress\n"
      ],
      "metadata": {
        "id": "SDpITHpkSi_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user= get_user(\"mohamed_rami\")\n"
      ],
      "metadata": {
        "id": "lKFM2QgRrXSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b1e290-a80f-4919-f317-fe8a83093658"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item(namespace=['mohamed_rami'], key='profile', value={'content': '{\\n  \"name\": \"Mohamed Rami Hamrouni\",\\n  \"title\": \"AI Engineer\",\\n  \"technical_skills\": {\\n    \"SWE\": {\\n      \"name\": \"SWE\",\\n      \"subskills\": {\\n        \"data_structures\": {\\n          \"name\": \"Data Structures\",\\n          \"description\": \"Understanding of arrays, linked lists, trees, graphs, and their algorithms\",\\n          \"growth_note\": null,\\n          \"last_updated\": null,\\n          \"strengths\": [],\\n          \"weaknesses\": []\\n        },\\n        \"system_design\": {\\n          \"name\": \"System Design\",\\n          \"description\": \"Ability to design scalable, maintainable software systems and understand architecture trade-offs\",\\n          \"growth_note\": null,\\n          \"last_updated\": null,\\n          \"strengths\": [\\n            \"Designed modular multi-agent system with asynchronous agents and chain-of-thought reasoning for accuracy and efficiency\",\\n            \"Optimized RAG pipeline to fetch relevant documents swiftly for multi-agent tasks\"\\n          ],\\n          \"weaknesses\": []\\n        },\\n        \"api_design\": {\\n          \"name\": \"API Design\",\\n          \"description\": \"Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation\",\\n          \"growth_note\": null,\\n          \"last_updated\": null,\\n          \"strengths\": [],\\n          \"weaknesses\": []\\n        }\\n      }\\n    },\\n    \"ML\": {\\n      \"name\": \"ML\",\\n      \"subskills\": {\\n        \"fundamentals\": {\\n          \"name\": \"ML Fundamentals\",\\n          \"description\": \"Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs\",\\n          \"growth_note\": \"Consider improving skills in systematically tracking and optimizing vector search metrics like relevance and latency.\",\\n          \"last_updated\": \"2024-06-09T10:40:00+00:00\",\\n          \"strengths\": [],\\n          \"weaknesses\": [\\n            \"Limited experience with systematic optimization and metric tracking for vector search\"\\n          ]\\n        },\\n        \"ml_system_design\": {\\n          \"name\": \"ML System Design\",\\n          \"description\": \"Designing machine learning pipelines, feature engineering, model deployment, and monitoring\",\\n          \"growth_note\": \"Continue experimenting with hybrid search strategies and embedding tuning to further optimize RAG pipeline precision and recall.\",\\n          \"last_updated\": \"2024-06-09T10:27:00+00:00\",\\n          \"strengths\": [\\n            \"Implemented RAG pipelines on LangChain with FAISS and Pinecone integration\",\\n            \"Successfully tuned embeddings, applied metadata filtering, and hybrid search strategies to improve retrieval relevance\",\\n            \"Used memory and retriever chain features to maintain multi-step query context\"\\n          ],\\n          \"weaknesses\": []\\n        },\\n        \"ai\": {\\n          \"name\": \"AI / Advanced Topics\",\\n          \"description\": \"Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques\",\\n          \"growth_note\": null,\\n          \"last_updated\": null,\\n          \"strengths\": [\\n            \"Practices structured approach in fine-tuning LLMs to balance accuracy, generalization, and overfitting avoidance\"\\n          ],\\n          \"weaknesses\": []\\n        }\\n      }\\n    }\\n  },\\n  \"soft_skills\": {\\n    \"Behavioral\": {\\n      \"name\": \"Behavioral\",\\n      \"subskills\": {\\n        \"communication\": {\\n          \"name\": \"Communication\",\\n          \"description\": \"Ability to clearly express ideas, structure answers effectively, and listen actively\",\\n          \"growth_note\": null,\\n          \"last_updated\": \"2024-06-09T10:27:00+00:00\",\\n          \"strengths\": [\\n            \"Explains complex GenAI workflows and technical considerations clearly and concisely\"\\n          ],\\n          \"weaknesses\": []\\n        },\\n        \"teamwork\": {\\n          \"name\": \"Teamwork\",\\n          \"description\": \"Collaboration, conflict resolution, and working effectively within a team\",\\n          \"growth_note\": null,\\n          \"last_updated\": null,\\n          \"strengths\": [],\\n          \"weaknesses\": []\\n        },\\n        \"adaptability\": {\\n          \"name\": \"Adaptability\",\\n          \"description\": \"Ability to adjust to new challenges, unexpected questions, and changing scenarios\",\\n          \"growth_note\": null,\\n          \"last_updated\": null,\\n          \"strengths\": [],\\n          \"weaknesses\": []\\n        }\\n      }\\n    }\\n  }\\n}'}, created_at='2025-10-31T17:44:54.725000', updated_at='2025-11-03T19:40:32.681000')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user.model_dump()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLS_1jK9aoCW",
        "outputId": "fc137030-9bf7-48a6-936c-83b050c966da"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Mohamed Rami Hamrouni',\n",
              " 'title': 'AI Engineer',\n",
              " 'technical_skills': {'SWE': {'name': 'SWE',\n",
              "   'subskills': {'data_structures': {'name': 'Data Structures',\n",
              "     'description': 'Understanding of arrays, linked lists, trees, graphs, and their algorithms',\n",
              "     'strengths': [],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': None},\n",
              "    'system_design': {'name': 'System Design',\n",
              "     'description': 'Ability to design scalable, maintainable software systems and understand architecture trade-offs',\n",
              "     'strengths': ['Designed modular multi-agent system with asynchronous agents and chain-of-thought reasoning for accuracy and efficiency',\n",
              "      'Optimized RAG pipeline to fetch relevant documents swiftly for multi-agent tasks'],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': None},\n",
              "    'api_design': {'name': 'API Design',\n",
              "     'description': 'Design and implementation of RESTful or GraphQL APIs with proper versioning, error handling, and documentation',\n",
              "     'strengths': [],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': None}}},\n",
              "  'ML': {'name': 'ML',\n",
              "   'subskills': {'fundamentals': {'name': 'ML Fundamentals',\n",
              "     'description': 'Core machine learning concepts, metrics, model evaluation, and bias-variance tradeoffs',\n",
              "     'strengths': [],\n",
              "     'weaknesses': ['Limited experience with systematic optimization and metric tracking for vector search'],\n",
              "     'growth_note': 'Consider improving skills in systematically tracking and optimizing vector search metrics like relevance and latency.',\n",
              "     'last_updated': datetime.datetime(2024, 6, 9, 10, 40, tzinfo=TzInfo(UTC))},\n",
              "    'ml_system_design': {'name': 'ML System Design',\n",
              "     'description': 'Designing machine learning pipelines, feature engineering, model deployment, and monitoring',\n",
              "     'strengths': ['Implemented RAG pipelines on LangChain with FAISS and Pinecone integration',\n",
              "      'Successfully tuned embeddings, applied metadata filtering, and hybrid search strategies to improve retrieval relevance',\n",
              "      'Used memory and retriever chain features to maintain multi-step query context'],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': 'Continue experimenting with hybrid search strategies and embedding tuning to further optimize RAG pipeline precision and recall.',\n",
              "     'last_updated': datetime.datetime(2024, 6, 9, 10, 27, tzinfo=TzInfo(UTC))},\n",
              "    'ai': {'name': 'AI / Advanced Topics',\n",
              "     'description': 'Deep learning, advanced AI architectures, applied research topics, and specialized ML techniques',\n",
              "     'strengths': ['Practices structured approach in fine-tuning LLMs to balance accuracy, generalization, and overfitting avoidance'],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': None}}}},\n",
              " 'soft_skills': {'Behavioral': {'name': 'Behavioral',\n",
              "   'subskills': {'communication': {'name': 'Communication',\n",
              "     'description': 'Ability to clearly express ideas, structure answers effectively, and listen actively',\n",
              "     'strengths': ['Explains complex GenAI workflows and technical considerations clearly and concisely'],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': datetime.datetime(2024, 6, 9, 10, 27, tzinfo=TzInfo(UTC))},\n",
              "    'teamwork': {'name': 'Teamwork',\n",
              "     'description': 'Collaboration, conflict resolution, and working effectively within a team',\n",
              "     'strengths': [],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': None},\n",
              "    'adaptability': {'name': 'Adaptability',\n",
              "     'description': 'Ability to adjust to new challenges, unexpected questions, and changing scenarios',\n",
              "     'strengths': [],\n",
              "     'weaknesses': [],\n",
              "     'growth_note': None,\n",
              "     'last_updated': None}}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Coach Agent**"
      ],
      "metadata": {
        "id": "ndx5K4EbmF2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COACH_SYSTEM_PROMPT = \"You are a coach aiming to improve candidate skills in a recruitment\""
      ],
      "metadata": {
        "id": "d0kiXtF7aq60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data = user.model_dump()\n",
        "\n",
        "weaknesses_dict = {}\n",
        "\n",
        "print(\"Technical Skill Weaknesses:\")\n",
        "technical_weaknesses = {}\n",
        "for skill_name, skill_data in user_data.get(\"technical_skills\", {}).items():\n",
        "    subskill_weaknesses = {}\n",
        "    for subskill_name, subskill_data in skill_data.get(\"subskills\", {}).items():\n",
        "        if subskill_data.get(\"weaknesses\"):\n",
        "            subskill_weaknesses[subskill_name] = subskill_data[\"weaknesses\"]\n",
        "            print(f\"    {subskill_name}:\")\n",
        "            for weakness in subskill_data[\"weaknesses\"]:\n",
        "                print(f\"      - {weakness}\")\n",
        "    if subskill_weaknesses:\n",
        "        technical_weaknesses[skill_name] = subskill_weaknesses\n",
        "weaknesses_dict[\"technical_skills\"] = technical_weaknesses\n",
        "\n",
        "\n",
        "print(\"\\nSoft Skill Weaknesses:\")\n",
        "soft_weaknesses = {}\n",
        "for skill_name, skill_data in user_data.get(\"soft_skills\", {}).items():\n",
        "    subskill_weaknesses = {}\n",
        "    for subskill_name, subskill_data in skill_data.get(\"subskills\", {}).items():\n",
        "        if subskill_data.get(\"weaknesses\"):\n",
        "            subskill_weaknesses[subskill_name] = subskill_data[\"weaknesses\"]\n",
        "            print(f\"    {subskill_name}:\")\n",
        "            for weakness in subskill_data[\"weaknesses\"]:\n",
        "                print(f\"      - {weakness}\")\n",
        "    if subskill_weaknesses:\n",
        "        soft_weaknesses[skill_name] = subskill_weaknesses\n",
        "weaknesses_dict[\"soft_skills\"] = soft_weaknesses\n",
        "\n",
        "print(\"\\nWeaknesses Dictionary:\")\n",
        "print(weaknesses_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GURDxjQImyfD",
        "outputId": "58717522-5ee6-4d83-81e5-9e14a40e2700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Technical Skill Weaknesses:\n",
            "    system_design:\n",
            "      - Limited focus on production-level reliability, error handling, monitoring, and dynamic model/provider routing.\n",
            "    fundamentals:\n",
            "      - Prompt optimization mostly via intuition, lacking structured testing or metrics.\n",
            "    ml_system_design:\n",
            "      - Minimal error handling, lack of monitoring and automated fallback in ML pipeline deployments.\n",
            "\n",
            "Soft Skill Weaknesses:\n",
            "\n",
            "Weaknesses Dictionary:\n",
            "{'technical_skills': {'SWE': {'system_design': ['Limited focus on production-level reliability, error handling, monitoring, and dynamic model/provider routing.']}, 'ML': {'fundamentals': ['Prompt optimization mostly via intuition, lacking structured testing or metrics.'], 'ml_system_design': ['Minimal error handling, lack of monitoring and automated fallback in ML pipeline deployments.']}}, 'soft_skills': {}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X93TQE56nHte"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}